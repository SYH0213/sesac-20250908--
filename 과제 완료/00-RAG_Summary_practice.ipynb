{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcd7b13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER\n",
      "01 RAG 이해하기\n",
      "\n",
      "학습 목표\n",
      "RAG(Retrieval-Augmented Generation)는 문서 로드, 검색, 답변 생성의 투명한 과정을 통해 할루시네이션 현상을 줄이고, 최신 정보와 신뢰할 수 있는 외부 데이터를 활용해 응답 정확도를 대폭 향상시킴으로써 GPT 모델의 한계를 극복하기 위한 기술입니다. RAG는 프롬프트 엔지니어링이나 파인 튜닝보다 구현이 용이하여 실용적이며, 사용자가 원하는 대로 데이터베이스와 모델을 커스터마이즈할 수 있어 특정 도메인에 특화된 챗봇을 제작할 수 있는 강력한 도구입니다. 그러한 RAG를 사용해야 하는 이유에 관해 알아보겠습니다.\n",
      "\n",
      "(01) RAG를 사용해야 하는 이유\n",
      "ChatGPT는 2022년 11월 등장하자마자 순식간에 많은 사용자를 확보했습니다. 2023년 11월에는 GPTs 스토어가 출시되어 GPT의 기능을 플러그인으로 제작하고 배포할 수 있게 되었고, 여러 고급 기능이 보완되면서 사용자들은 단순히 질문하고 답변받는 것에서 더 나아가 전문적인 영역까지 ChatGPT를 적극적으로 활용하기 시작했습니다. 이러한 과정에서 점차 다음과 같은 문제점들이 드러나기 시작했습니다.\n",
      "\n",
      "1. ChatGPT는 최신 정보가 학습되어 있지 않습니다.\n",
      "2. 개인이나 회사의 내부 데이터가 학습되어 있지 않아, 특정 도메인(개인 정보, 회사 내부 정보)에 대한 질문에는 기대하는 답변을 얻을 수 없습니다.\n",
      "3. ChatGPT에 개인이나 회사 정보를 담은 문서를 업로드하면 보안상 문제가 될 수 있습니다.\n",
      "4. 문서의 양이 많아질수록 할루시네이션 현상이 발생하기 쉽습니다.\n",
      "\n",
      "ChatGPT의 한계를 보완하기 위해 주목받은 RAG\n",
      "RAG는 ChatGPT의 한계를 보완하기 위해 주목받기 시작한 기술입니다. RAG란 Retrieval-Augmented Generation의 줄임말로, 검색(Retrieval), 증강(Augmented), 생성(Generation)이라는 의미를 담고 있으며, 거대 언어 모델(LLM; Large Language Model)이 외부의 신뢰할 수 있는 지식 데이터베이스를 참조하여 최적화된 응답을 생성하는 기술입니다.\n",
      "\n",
      "RAG의 다양한 방법론을 활용하여 지속적으로 업그레이드하면 ChatGPT만 사용했을 때 50점 수준이었던 답변의 품질을 80점, 90점대로 끌어올릴 수 있습니다. 적절한 RAG를 적용하면 앞서 언급된 문제점들을 다음과 같이 개선할 수 있습니다.\n",
      "\n",
      "1. 최신 정보를 기반으로 답변할 수 있으며, LLM이 정보를 찾을 수 없는 경우 '검색' 기능을 활용해 답변을 제공할 수 있습니다.\n",
      "2. 회사 내부에 데이터베이스를 구현함으로써 개인이나 회사의 내부 데이터를 참고하여 GPT가 답변할 수 있습니다.\n",
      "3. 문서를 내부 데이터베이스에 저장하고 지속적으로 데이터를 축적할 수 있으며, 저장된 데이터베이스에서 원하는 정보를 검색한 후 이를 바탕으로 답변을 생성할 수 있습니다.\n",
      "4. 저장된 데이터베이스에서 답변의 출처를 역으로 검색하고 검증하는 방식으로 할루시네이션 현상을 줄일 수 있습니다.\n",
      "\n",
      "따라서 RAG를 사용하면 GPT가 사전 학습한 내용뿐 아니라 새롭게 축적되는 데이터베이스를 기반으로도 답변할 수 있어, 사용자는 데이터베이스만 업데이트하면 더 높은 품질의 최신 답변을 얻을 수 있습니다. 결과적으로 개인 맞춤형 챗봇이나 회사 내부 데이터에 특화된 챗봇과 같이 특정 도메인에 최적화된 챗봇을 자유롭게 생성할 수 있습니다.\n",
      "\n",
      "이해를 돕기 위해 예시를 들어 보겠습니다. RAG를 사용하기 전 ChatGPT에게 다음과 같이 질문해 보았습니다.\n",
      "“서울특별시에 사는 테디 아버지 이름이 뭐야?\"\n",
      "ChatGPT는 이러한 개인적인 질문을 받으면 굉장히 황당할 겁니다. 테디가 누구인지, 그의 아버지 이름이 뭔지 어떻게 알겠냐고요. 이런 경우 모른다고 답하거나 답변하는 과정에서 잘못된 정보를 생성(할루시네이션)할 가능성이 높습니다. 하지만 다음과 같은 가족관계증명서를 GPT에게 주면 어떻게 될까요? GPT는 자료를 참고해서 테디 아버지 이름은 '폴'이라고 정확한 답변을 제공할 수 있을 것입니다.\n",
      "\n",
      "이처럼 RAG는 GPT가 사전 학습된 지식에만 의존하지 않고 참고할 만한 자료를 주면 그것을 토대로 답변하기 때문에 훨씬 더 정확합니다. 쉽게 말해 사전 학습된 GPT에 정보 검색 기능을 추가한 것이죠. 검색 대상은 문서와 인터넷은 물론 다양한 도메인일 수도 있습니다.\n",
      "\n",
      "따라서 우리가 할 일은 이러한 다양한 정보 검색 기술을 활용해서 RAG 시스템을 점점 고도화하는 것입니다. RAG가 발전할수록 답변의 정교함도 높아집니다. 예를 들어 관련된 모든 문서를 GPT에 제공하는 대신 핵심 정보만 요약해서 전달하면 훨씬 더 효율적으로 참고할 수 있겠죠. 이처럼 GPT가 참고할 데이터를 잘 정제하면 RAG 시스템의 성능을 높일 수 있습니다.\n",
      "\n",
      "커스터마이즈가 어려운 ChatGPT 내장 RAG 시스템\n",
      "ChatGPT를 어느 정도 사용해 본 사용자라면 자신도 모르게 RAG를 경험해 봤을 것입니다. 다음과 같이 ChatGPT에 문서를 업로드하고 질문하면 이를 기반으로 그럴듯한 답변을 제공하는데, 이는 ChatGPT에 내장된 자체 RAG 시스템 때문입니다. 하지만 이렇게 생성된 답변이 실제로 정확한 정보인지 확인하기는 어렵습니다.\n",
      "\n",
      "다음과 같이 한국 경제 전망에 대한 보고서 PDF 문서를 ChatGPT에 업로드하고, 특정 내용을 알려 달라고 요청해 보겠습니다. 보고서의 주요 내용을 그럴듯하게 답변하는데, 이 답변이 정말 해당 보고서에서 가져온 내용인지, 아니면 ChatGPT가 학습한 내용으로 적당히 둘러댄 답변인지 어떻게 분간할 수 있을까요?\n",
      "\n",
      "이 문서는 한국개발연구원(KDI)에서 발간한 2023년 하반기 경제전망 보고서입니다. 이 보고서는 국내외 경제 동향을 분석하고 중단기 경제 전망을 제공하며, 경제 전망에 대한 불확실성 요인과 대책을 연구하여 정부의 경제 정책 수립과 기업의 경영, 학계의 연구 활동에 도움을 주기 위해 작성되었습니다.\n",
      "보고서의 주요 내용은 다음과 같습니다:\n",
      "1. 현재의 경제 상황과 내년의 경제 전망을 다루며, 고금리 기조의 영향, 수출 회복세, 내수 둔화, 물가 상황, 취업자 수 변화 등에 대해 다룹니다.\n",
      "2. 2024년 국내경제 전망에서는 완만한 회복세를 예측하며, 성장률, 소비자 물가, 취업자 수, 경상수지 등 다양한 경제 지표에 대해 예측합니다.\n",
      "3. 재정정책, 통화정책, 금융정책 등의 정책 방향을 제시합니다.\n",
      "4. 위험 요인으로는 국제유가 변동, 중국의 경제 상황 변화 등 대외 불확실성이 높은 점을 지적하며, 이에 대한 대응 방안을 모색합니다.\n",
      "이 보고서는 정부 및 기업의 정책 결정에 중요한 정보를 제공하며, 경제 상황에 대한 깊은 이해와 미래 전망에 대한 지침을 담고 있습니다.\n",
      "\n",
      "문서 내용에 대해 더 자세히 알아보고자 세부 내용을 선택하여 다시 질문하고, 반드시 문서의 내용을 바탕으로 답변해 달라고 요청했습니다. 그러나 ChatGPT는 해당 내용에 대한 구체적인 데이터를 제공하지 않는다는 이상한 답변을 내놓았습니다. 문서에 분명히 해당 내용이 있음에 도 ChatGPT가 관련 정보를 찾지 못하는 현상이 발생했습니다.\n",
      "보고서에서는 유로존의 전체 및 청년 실업률에 대한 구체적인 데이터를 제공하지 않습니다. 이 문서는 한국의 경제 상황과 전망에 초점을 맞추고 있어, 유로존의 실업률과 같은 특정 국제 경제 지표에 대한 세부 수치는 포함되어 있지 않습니다. 유로존의 실업률 정보가 필요하시다면, 유럽연합 통계국(Eurostat)의 공식 웹사이트에서 최신 데이터를 찾으실 수 있을 것입니다.\n",
      "\n",
      "일반적으로 ChatGPT에 문서를 입력하고 질문하면 답변이 잘 나온다고 생각하지만, 실제로는 조금만 더 구체적으로 질문하면 문서의 내용과 전혀 다른 답변이 나오는 할루시네네이션이 발생하기도 합니다.\n",
      "\n",
      "II. 세계경제 동향\n",
      "실업률이 낮은 수준을 지속하는 등 노동시장 관련 지표는 양호한 흐름을 유지\n",
      "- 3/4분기 유로존의 전체 및 청년실업률은 전분기에 이어 각각 6.5%, 14.0%의 낮은 수준을 기록\n",
      "- 2/4분기 임금상승률이 높은 수준을 지속하는 가운데, 장기실업자 비중은 하향 안정세를 유지\n",
      "\n",
      "ChatGPT에서 RAG가 작동하는 과정은 OpenAI에서 공개하고 있지 않아 사용자가 이를 직접 제어할 수는 없습니다. 따라서 문서를 ChatGPT가 최대한 잘 검색할 수 있는 형태로 변경하는 것이 현재로서는 최선의 방법입니다. 예를 들어 자주 하는 질문을 FAQ로 만들거나 PDF, DOCX, HWP 등의 문서를 마크다운 형식으로 작성하는 방식이 있습니다. 하지만 모든 문서를 이렇게 변경하는 것은 많은 시간과 노력이 필요한 작업이라 현실적으로 어렵습니다. 이러한 한계를 극복하기 위해 우리는 LangChain을 이용해 RAG 시스템을 직접 구축해 볼 것입니다.\n",
      "\n",
      "(02) RAG의 기막힌 능력\n",
      "RAG는 장점이 큰 기술이지만 LLM을 처음 접하는 사람들이 RAG 도입을 주저하는 이유는 주로 복잡해 보이는 용어와 기술적 장벽 때문인 것 같습니다. 그러나 기본 원리만 이해한다면 RAG는 생각보다 어려운 기술이 아닙니다.\n",
      "\n",
      "플러그인처럼 교체하는 방식의 쉬운 구현\n",
      "다음은 언어 모델의 성능 향상을 위한 각 기술의 난이도를 비교한 그래프입니다. 가장 오른쪽에 있는 완전 파인 튜닝(Full Fine-Tuning)은 다소 전문적인 영역이기 때문에 개인이 수행하기에는 어려울 수 있습니다. PEFT(Parameter-Efficient Fine-Tuning) 역시 파인 튜닝의 한 종류이지만, 충분한 시간과 노력을 들인다면 개인적으로 시도해 볼 수 있는 수준입니다.\n",
      "RAG는 코드 작성이 필요 없는 프롬프트 엔지니어링과 비교해도 구현 난이도가 그리 높지 않은데, 이는 앞으로 학습할 8단계의 세부 모듈을 플러그인처럼 교체하는 방식으로 구현할 수 있기 때문입니다.\n",
      "\n",
      "최신 정보를 기반으로 답변\n",
      "그래프를 보면 RAG가 최신 정보에 대한 답변에서도 월등히 뛰어난 성능을 보여 주고 있습니다. 이는 사용자가 직접 원하는 최신의 문서를 데이터베이스에 넣어 업데이트할 수 있기 때문입니다.\n",
      "\n",
      "답변 과정을 투명하게 확인 및 해석 가능\n",
      "RAG는 전 과정을 모니터링하고 추적할 수 있으며, 각 단계를 상세히 분석하고 조정할 수 있습니다. 이는 모든 과정을 사용자가 직접 설계하기 때문에 답변을 해석하는 과정에서도 잘 나온 답변은 왜 잘 나왔는지, 제대로 된 답변을 얻지 못했다면 그 이유는 무엇인지를 직접 확인할 수 있기 때문입니다. 다음 그래프에서도 볼 수 있듯이, RAG는 답변의 투명성과 해석 능력 측면에서 압도적인 성능을 보여 주고 있습니다.\n",
      "\n",
      "실제 예시를 통해 답변 추적 과정을 확인해 보겠습니다. LLM의 동작 과정을 추적하는 도구인 LangSmith에서 '삼성전자에서 자체 개발한 AI의 이름은?'이라고 질문을 던지면 왼쪽 추적 과정에서 답변 도출까지의 세부 과정, 소요 시간, 토큰 수 등을 확인할 수 있습니다. 이는 간단한 예시이지만, 추후 더 복잡한 설계를 진행한다고 해도 이러한 과정을 더욱 심도 있게 분석할 수 있습니다.\n",
      "실제로 Retriever를 클릭하면 질문(query)이 입력되었을 때 어떤 문서(DOCUMENTS)의 어느 구절에서 관련 내용을 검색했는지를 다음과 같이 상세하게 확인할 수 있습니다.\n",
      "또한 해당 문서들을 각각 클릭해서 열어 보면 실제 텍스트 내용까지도 확인할 수 있습니다. 이렇게 세부 과정을 확인하면 답변이 잘 나오지 않았을 경우 그 원인을 추적하여 결과를 개선할 수 있습니다.\n",
      "\n",
      "할루시네이션 감소\n",
      "RAG는 LLM의 대표적 부작용인 할루시네이션을 감소시키는 데도 효과적입니다. 유효한 정보만을 기반으로 답변을 도출하도록 강제하거나, 주어진 문서에서만 답변의 출처를 찾도록 하는 방식으로 오류를 줄일 수 있기 때문입니다. 다음 그래프를 보면 할루시네이션 방지에 있어 RAG가 가장 큰 영향을 미치는 것을 확인할 수 있습니다.\n",
      "\n",
      "(03) LangChain을 이용한 RAG 시스템 구축\n",
      "LangChain(랭체인)은 대규모 언어 모델로 구동되는 애플리케이션을 개발하기 위한 프레임워크입니다. 즉, GPT와 같은 언어 모델과 우리가 만들고자 하는 서비스나 프로세스를 쉽게 연결해 주는 도구입니다.\n",
      "\n",
      "ChatGPT는 GPT라는 언어 모델을 기반으로 한 대화형 AI 플랫폼입니다. 우리는 이 똑똑한 GPT를 채팅만 하는 데 그치지 않고, 다양한 서비스에 활용합니다. 예를 들면 여행 서비스를 운영하는 경우 GPT로 자동 여행 계획을 세워 주는 서비스를 만들거나, 차량 렌트 서비스를 운영하는 경우 GPT로 고객 응대 챗봇을 만듭니다. 이렇게 똑똑한 GPT의 두뇌를 원하는 작업 흐름에 접목하여 체인으로 엮는 형태로 만드는 것이 바로 LangChain입니다.\n",
      "\n",
      "GPT로 어떤 문서에 기반한 Q&A 시스템을 만들려면 문서를 그냥 넣기만 해서는 안 되고, 문서 안에 있는 텍스트를 읽어들일 수 있게끔 별도로 작업을 해 주어야 하는데, LangChain으로는 이런 작업을 너무 쉽게 할 수 있습니다. 또한 어떤 동작을 파이썬 코드로 처음부터 끝까지 작성하려면 시간이 굉장히 오래 걸리지만, LangChain에서는 코드 한두 줄로 편리하게 구현할 수 있습니다.\n",
      "\n",
      "일단 LangChain만 배워 두면 어떤 데이터베이스를 쓸지, 어떤 임베더(텍스트 같은 정보를 연산 가능한 수치로 변환해 주는 도구)를 쓸지, 어떤 종류의 문서를 업로드할지 등만 결정해서 가져다 쓰면 되니 데이터베이스 전문 개발사들도 LangChain을 도입하기 위해 노력하고 있고, LangChain을 도입하는 분야와 그 산업의 크기는 점점 더 커지고 있습니다.\n",
      "\n",
      "LLM을 이용해 서비스를 개발한다고 하면 LangSmith, LangGraph, LangServe 등의 도구도 필요합니다. 이 모든 것을 통합한 LangChain 생태계를 앞으로 하나하나 구현해 보겠습니다.\n",
      "\n",
      "LangChain으로 구현할 RAG 시스템 전체 프로세스\n",
      "ChatGPT는 자체 RAG 시스템을 통해 답변을 제공하지만, 더 나은 답변을 위해 세부 알고리즘을 조정할 수 없다는 문제가 있습니다. 이제 우리는 LangChain을 통해 RAG의 모든 세부 프로세스를 한 땀 한 땀 구현할 것입니다. 한마디로 '튜닝'을 하는 것이죠. 우리가 원하는 형태의 답변을 얻을 때까지 각 과정을 투명하게 개선하고, 그 방법론을 체계적으로 정립해 놓으면 다양한 비즈니스 환경에서도 얼마든지 활용 가능한 수준의 성능에 도달할 수 있습니다.\n",
      "다음은 RAG 시스템의 전체 프로세스입니다. 이 그림이 처음에는 복잡해 보일 수 있지만, 각 세부 과정을 하나씩 익혀 나가면 어렵지 않게 이해할 수 있습니다.\n",
      "\n",
      "RAG 프로세스의 사전 단계 이해하기\n",
      "RAG를 쓰는 목적을 이해하기 위해 GPT로 질문을 해서 답변을 받는 과정을 살펴봅시다. 먼저 사용자가 GPT에 “삼성전자가 신규 개발한 AI가 뭐야?\" 같은 질문을 입력합니다. 사용자의 질문이 프롬프트에 들어오면 LLM에 전달되어 답변을 출력합니다. 이때 GPT는 아무런 참고할 만한 정보를 따로 받지 않았기 때문에 사전 학습된 내용만으로 답변을 줄 수밖에 없습니다. 만약 GPT가 현재 상황과 다른 오래된 정보만 알고 있다면 답변에서 할루시네이션이 일어나기 십상입니다.\n",
      "\n",
      "반면 RAG에서는 미리 참고할 정보(가령 PDF, CSV 등)를 데이터베이스나 문서 형태로 저장해 둡니다. 사용자가 질문을 입력하면 리트리버(retriever)가 해당 질문과 유사성이 높은 문서를 데이터베이스에서 찾아 반환하고, 이를 프롬프트에 포함하여 LLM이 컨텍스트(context)에서 필요한 내용을 검색해서 답변을 생성하도록 돕습니다.\n",
      "\n",
      "그렇다면 참고할 정보를 어떻게 가져올까요? 가령 '인공지능 산업의 최신 동향'이라는 23페이지 분량의 보고서 PDF 파일을 업로드했다고 가정해 보겠습니다. 만약 프롬프트에서 이 파일의 모든 정보를 한 번에 참고한다면, 사용자가 질문을 할 때마다 23페이지나 되는 내용이 모두 프롬프트 입력으로 들어가 버립니다. 그러면 질문을 처리하는 비용이 비싸지기도 하거니와 GPT에 너무 많은 정보를 제공한 탓에 중요한 정보를 찾지 못할 수도 있습니다. 그래서 업로드한 정보에서 관련성 있는 정보만 골라서 리트리버(retriever, 검색기)에 전달하는 것이 효율적입니다. 이 과정이 RAG 프로세스의 사전 단계에 해당합니다.\n",
      "\n",
      "사전 단계에서는 데이터 소스를 벡터 스토어로 사용하여 문서 로드-텍스트 분할-임베딩-저장이라는 네 단계를 진행합니다.\n",
      "- 1단계 | 문서 로드(Document Load): 외부 데이터 소스에서 필요한 문서를 불러와서 초기 처리를 합니다. 이것은 마치 학생이 공부하기 전에 책장에서 필요한 책을 여러 권 챙겨 오는 과정과 같습니다.\n",
      "- 2단계 | 텍스트 분할(Text Split): 로드된 문서를 처리 가능한 작은 단위인 청크(chunk)로 분할합니다. 두꺼운 책을 주제별로 나누어 Part나 Chapter로 구분하는 것과 유사합니다.\n",
      "- 3단계 | 임베딩(Embedding): 분할된 청크를 벡터 형태로 변환하여 문서의 의미를 수치화합니다. 자연어를 컴퓨터가 이해할 수 있는 수치로 변경하는 과정입니다.\n",
      "- 4단계 | 벡터 스토어 저장: 임베딩된 청크를 데이터베이스에 저장합니다. 임베딩된 벡터들을 데이터베이스에 저장합니다. 이는 요약된 키워드를 색인으로 뽑아서 나중에 빠르게 찾을 수 있게 정리해 두는 과정입니다.\n",
      "\n",
      "먼저 문서 로드 단계에서는 PDF, 엑셀, 논문, 이미지, 데이터베이스 등 문서를 로드합니다. 가령 PDF 파일을 로드하면 그 안에 있는 텍스트를 긁어 오는 작업을 합니다.\n",
      "그다음은 텍스트 분할입니다. '삼성전자가 신규 개발한 AI가 뭐야?'라는 질문에 답하려면 '인공지능 산업의 최신 동향' 보고서 PDF에서 18페이지의 일부 내용만 가져와서 답변하면 됩니다. 이처럼 전체 정보를 다 프롬프트에 쓰지 않고, 청크라는 단위로 내용을 분할합니다. 토큰 수를 기준으로 청크 크기를 지정하면, 해당 분량의 청크로 분할됩니다. 가령 청크 크기를 1,000토큰으로 잡고, 한 페이지에 청크가 세 개 정도 들어간다고 가정해 보겠습니다. 그러면 23페이지의 보고서 내용이 69개의 청크로 분할되어 저장됩니다.\n",
      "사용자 질문이 들어오면 질문의 내용과 각각의 청크에 대해 유사도 계산을 해서 가장 관련성이 높은 청크를 뽑아내는 작업을 합니다. 유사도를 계산하기 위해 각 청크의 값을 수학적인 표현으로 바꿔야 하는데 이것을 임베딩이라고 합니다. 자연어는 복잡하고 다양한 의미를 내포하고 있는데, 임베딩을 통해 텍스트를 정량화된 숫자 값으로 변환하면 컴퓨터가 문서의 내용과 의미를 더 잘 이해해서 처리할 수 있습니다.\n",
      "쉬운 예를 들어 임베딩을 설명해 보겠습니다. '매운맛', '신맛', '단맛'이라는 정보를 임베딩해서 각각 0.1, 0.7, 0.9와 같은 값을 매깁니다. 그러면 사용자가 '새콤달달한 맛'이라는 정보를 입력하면, '신맛'과 '단맛' 사이의 중간 지점인 0.8이라는 값을 매길 수 있습니다. 이렇게 되면 '새콤달달한 맛'에 대해 질문이 들어 왔을 때 이미 주어진 정보에는 이와 정확히 일치하는 표현이 없더라도 '신맛'이나 '단맛'에 대한 청크가 질문과 유사도가 높다고 판단할 수 있습니다.\n",
      "\n",
      "'인공지능 산업의 최신 동향' 같은 복잡하고 풍부한 텍스트의 정보는 하나의 숫자 표현으로 나타낼 수 없습니다. 그래서 여러 숫자의 좌표 집합인 벡터(vector)로 표현합니다. 우리가 사용할 OpenAI의 임베딩의 벡터는 1536차원입니다. 이 말은, 한 단어든 문장이든 단락이든 이를 나타내는 벡터 값에 1,536개의 숫자가 들어간다는 뜻입니다. 알고리즘에 따라 임베딩한 벡터 값의 개수가 달라지는데, 표현이 풍부할수록 정교하게 유사도를 비교할 수 있겠지만 그 대신 리소스를 더 많이 소모합니다.\n",
      "앞서 청크 크기를 기준으로 정보를 몇 개의 토큰 단위로 나눌지 정한다고 설명했는데요. 보통 분할된 청크 끝부분에서 맥락이 이어질 수 있도록 일부를 겹쳐서 분할합니다. 이를 청크 오버랩(chunk overlap)이라고 합니다.\n",
      "청크의 벡터 값으로 유사도 계산을 하는 예시를 보여 드리겠습니다. 다음과 같이 세 개의 단락(청크)이 있고, '시장조사기관 IDC가 예측한 AI 소프트웨어 시장의 연평균 성장률은 어떻게 되나요?'라는 사용자 질문이 들어오면 각 단락과 질문이 임베딩되어 벡터 값이 매겨집니다. 그러면 벡터 값을 이루는 숫자 사이의 차이(거리)를 계산할 수 있어 질문의 벡터 값과 가장 거리가 가까운(즉, 가장 유사한) 단락이 프롬프트의 컨텍스트로 전달됩니다.\n",
      "\n",
      "LLM의 질문과 답변을 처리할 때와 마찬가지로 임베딩할 때도 비용이 발생합니다. 물론 답변에 소요되는 것보다는 부담이 덜하지만, 프로그램을 실행할 때마다 매번 임베딩을 한다면 계속 비용이 발생하는 셈입니다. 그래서 각 청크에 임베딩된 값을 벡터 스토어(vector store)에 저장해 두고, 데이터베이스에 검색어로 쿼리를 요청할 때마다 가져올 수 있게 합니다.\n",
      "이처럼 문서를 로드해서 텍스트를 청크 단위로 분할하고 각각의 청크를 임베딩해서 유사도 계산을 위한 벡터 값을 저장하는 과정을 전처리 과정(pre-process)이라고 합니다.\n",
      "\n",
      "RAG 프로세스의 실행 단계 이해하기\n",
      "이번에는 사전 단계 이후의 실행(runtime) 단계를 살펴보겠습니다.\n",
      "- 5단계 | 리트리버: 질문이 주어지면, 이와 관련된 벡터를 벡터 데이터베이스에서 검색합니다. 질문에 가장 잘 맞는 책의 Chapter를 찾는 것과 유사합니다.\n",
      "- 6단계 | 프롬프트: 검색된 정보를 바탕으로 언어 모델을 위한 질문을 구성합니다. 이는 정보를 바탕으로 어떻게 질문할지 결정하는 과정입니다.\n",
      "- 7단계 | LLM: 구성된 프롬프트를 사용하여 언어 모델이 답변을 생성합니다. 즉, 수집된 정보를 바탕으로 과제나 보고서를 작성하는 학생과 같습니다.\n",
      "- 8단계 | 체인 생성: 이전의 모든 과정을 하나의 파이프라인으로 묶어 주는 체인(chain)을 생성합니다.\n",
      "\n",
      "다섯 번째 리트리버(retriever) 단계는 벡터 데이터베이스에서 사용자 질문과 관련된 문서를 검색하는 핵심 과정입니다. 사용자가 질문을 입력하면 이를 임베딩 단계와 동일한 방식으로 벡터로 변환합니다. 이렇게 변환된 질문 벡터는 미리 준비된 데이터베이스의 문서 벡터들과 비교되어 유사성이 계산됩니다. 코사인 유사성(cosine similarity)이나 MMR(Max Marginal Relevance) 같은 알고리즘이 이 비교 과정에서 활용되며, 이를 통해 질문과 가장 관련이 깊은 단락들을 선별해 냅니다. 이때 k 값을 설정하여 선택할 청크의 수를 조절할 수 있습니다. 이렇게 찾아 낸 문서의 내용과 메타데이터는 다음 단계인 프롬프트 생성으로 넘어갑니다.\n",
      "리트리버의 성능은 전체 시스템의 응답 품질과 직결됩니다. 관련성 높은 정보를 정확히 찾아내야 유용한 답변이 가능하기 때문입니다. 또한 효율적인 검색 알고리즘을 활용해 전체 응답 시간을 단축시켜 사용자 경험을 개선하는 것도 중요한데, 필요한 정보만 추출하는 과정은 시스템 자원의 사용을 최적화하고 불필요한 데이터 처리를 최소화할 수 있어 전체 시스템의 효율성을 높이는 데 중요한 역할을 합니다.\n",
      "\n",
      "여섯 번째 프롬프트 단계는 리트리버가 검색해 온 문서들을 바탕으로 언어 모델이 사용할 질문이나 명령을 만드는 과정입니다. 여러 문서에서 가져온 정보들은 다양한 관점이나 내용을 담고 있을 수 있는데, 이 단계에서 이런 정보들을 하나로 통합하고 언어 모델이 특정 컨텍스트 안에서 제대로 작동하도록 안내하는 역할을 합니다. 잘 구성된 프롬프트는 모델이 더 정확하고 관련성 높은 답변을 만들어 낼 수 있는 중요한 토대가 됩니다.\n",
      "\n",
      "일곱 번째 LLM(Large Language Model) 단계에서는 앞서 구성된 프롬프트를 입력으로 받아 대규모 언어 모델을 통해 실제 응답을 생성합니다. 이 과정에서 언어 모델의 능력을 최대한 활용하여 사용자 질문에 대한 정확하고 자연스러운 답변이 만들어집니다. 이 단계는 앞선 모든 과정의 결과물을 실제 사용자가 이해할 수 있는 형태로 변환하는 최종 관문이라 할 수 있습니다.\n",
      "\n",
      "마지막으로 체인 생성 단계는 LCEL(LangChain Expression Language) 문법을 활용해 앞서 설명한 일곱 단계를 하나로 묶어 완전한 RAG 파이프라인으로 조립하는 단계입니다. 체인의 구조를 좀 더 구체적으로 살펴보겠습니다. 사용자 질문은 두 갈래로 나뉘어 처리됩니다. 하나는 리트리버로 전달되어 필요한 정보를 검색하는 데 쓰이고, 하나는 RunnablePassthrough() 메서드를 통해 바로 프롬프트의 질문(question)으로 들어갑니다. 리트리버에 전달된 질문은 임베딩 표현으로 변환되어 벡터 스토어의 데이터베이스와 유사도 계산을 해서 가장 관련성이 높은 단락을 뽑아냅니다. 이렇게 선정한 k개의 단락은 프롬프트의 컨텍스트(context)로 전달되어 최종 응답 생성의 근거 자료로 활용됩니다.\n",
      "\n",
      "체인 생성과 질의를 코드로 간단히 나타내면 다음과 같습니다.\n",
      "chain = (\n",
      "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
      "    | prompt | llm | StrOutputParser()\n",
      ")\n",
      "question = \"삼성전자가 신규 개발한 AI의 이름은?\"\n",
      "response = chain.invoke(question)\n",
      "print(response)\n",
      "\n",
      "직접 커스터마이즈한 RAG의 높은 성능\n",
      "다음은 OpenAI 데브 데이(Dev Day) 프레젠테이션에서 공개된 내용의 일부입니다. AI로부터 좋은 답변을 얻기 위해서는 프롬프트 엔지니어링만으로는 성능을 올리는 데 한계가 있습니다. GPT는 전 세계 사람들이 사용하는 모델이기 때문에 평균적으로 답변을 잘하게끔 설계된 범용 모델입니다. 이러한 GPT 모델에 RAG를 활용해 컨텍스트를 더 최적화하면 문맥을 보완하여 더 구체적인 답변을 얻을 수 있으며, 여기에 파인 튜닝(미세 조정)을 더하면 원래 모델이 가진 잠재력을 최고 수준으로 끌어올려 상세한 답변을 얻음과 동시에 할루시네이션 현상도 줄일 수 있습니다.\n",
      "\n",
      "다음 그래프는 RAG에 다양한 기법을 적용하는 것에 따라 성능이 점진적으로 향상되는 수치를 보여 줍니다. 가장 기본적인 방법만 사용했을 때 45%였던 정확도는 추가적인 기법들의 적용에 따라 65%, 85%까지 향상되었고, 프롬프트 엔지니어링까지 더해져 최종적으로 98%의 정확도를 달성했습니다. 우리가 지금까지 사용해 온 ChatGPT의 실제 능력치가 45% 수준에 불과했다는 사실이 놀랍지 않나요?\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import pathlib\n",
    "import httpx\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "# Retrieve and encode the PDF byte\n",
    "file_path = pathlib.Path(\"data/RAG_25-42.pdf\")\n",
    "\n",
    "\n",
    "# Upload the PDF using the File API\n",
    "sample_file = client.files.upload(\n",
    "    file=file_path,\n",
    ")\n",
    "\n",
    "prompt = \"\"\"pdf파일에서 텍스트 내용을 추출해줘. pdf에는 다양한 텍스트와 이미지, 차트가 포함되어 있어.\n",
    "            텍스트만 추출해줘.\n",
    "        \"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-pro\", contents=[sample_file, prompt]\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db09b7ea",
   "metadata": {},
   "source": [
    "## Stuff\n",
    "\n",
    "Summary하는 가장 기초적인 방법.\n",
    "문서 전체를 llm에 던지고 요약."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f30b12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please summarize the sentence according to the following REQUEST.\n",
      "REQUEST:\n",
      "1. Summarize the main points in bullet points in KOREAN.\n",
      "2. Each summarized sentence must start with an emoji that fits the meaning of the each sentence.\n",
      "3. Use various emojis to make the summary more interesting.\n",
      "4. Translate the summary into KOREAN if it is written in ENGLISH.\n",
      "5. DO NOT translate any technical terms.\n",
      "6. DO NOT include any unnecessary information.\n",
      "\n",
      "CONTEXT:\n",
      "\u001b[33;1m\u001b[1;3m{context}\u001b[0m\n",
      "\n",
      "SUMMARY:\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"teddynote/summary-stuff-documents-korean\")\n",
    "prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "13017f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_teddynote.callbacks import StreamingCallback\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    streaming=True,\n",
    "    temperature=0,\n",
    "    callbacks=[StreamingCallback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "91a66aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "docs = [Document(page_content=response.text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1b0da78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12934\n"
     ]
    }
   ],
   "source": [
    "print(len(docs[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "18d56f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 📚 RAG(Retrieval-Augmented Generation)는 GPT 모델의 한계를 극복하기 위한 기술로, 최신 정보와 신뢰할 수 있는 외부 데이터를 활용하여 응답 정확도를 향상시킴.  \n",
      "- 🔍 RAG는 검색, 증강, 생성의 과정을 통해 할루시네이션 현상을 줄이고, 사용자가 원하는 데이터베이스와 모델을 커스터마이즈할 수 있는 강력한 도구임.  \n",
      "- ⚙️ RAG는 구현이 용이하여, 사용자가 전문적인 영역에서도 ChatGPT를 활용할 수 있도록 도와줌.  \n",
      "- 🛡️ RAG를 통해 최신 정보 기반의 답변, 내부 데이터 활용, 문서 저장 및 검증 기능을 제공하여 ChatGPT의 한계를 보완할 수 있음.  \n",
      "- 🧩 RAG 시스템은 LangChain을 통해 구축할 수 있으며, 다양한 데이터베이스와 연결하여 효율적인 Q&A 시스템을 만들 수 있음.  \n",
      "- 📈 RAG의 성능은 다양한 기법을 적용함에 따라 점진적으로 향상되며, 최종적으로 높은 정확도를 달성할 수 있음."
     ]
    }
   ],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "stuff_chain = create_stuff_documents_chain(llm, prompt)\n",
    "answer = stuff_chain.invoke({\"context\": docs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdc946d",
   "metadata": {},
   "source": [
    "## Map-Reduce\n",
    "\n",
    "문서를 페이지 혹은 일정한 청크 단위로 나눈 후 그 청크에 대한 부분 요약을 함\n",
    "\n",
    "->부분 요약들을 모은 데이터를 다시 요약하여 최종 요약을 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4149c728",
   "metadata": {},
   "source": [
    "### MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ccc13549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a professional main thesis extractor.\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Your task is to extract main thesis from given documents. Answer should be in same language as given document. \n",
      "\n",
      "#Format: \n",
      "- thesis 1\n",
      "- thesis 2\n",
      "- thesis 3\n",
      "- ...\n",
      "\n",
      "Here is a given document: \n",
      "\u001b[33;1m\u001b[1;3m{doc}\u001b[0m\n",
      "\n",
      "Write 1~5 sentences.\n",
      "#Answer:\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model_name=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "map_prompt = hub.pull(\"teddynote/map-prompt\")\n",
    "\n",
    "map_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9f7e130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_chain = map_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6a813f",
   "metadata": {},
   "source": [
    "docs를 스플릿해서 부분 요약할 수 있게 나눔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ebc90273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 청크 개수: 5\n",
      "청크 0 길이: 2754\n",
      "청크 1 길이: 2595\n",
      "청크 2 길이: 2777\n",
      "청크 3 길이: 2736\n",
      "청크 4 길이: 2242\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=3000,\n",
    "    chunk_overlap=200,   # 필요시 오버랩 조금 두기\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "chunks = splitter.split_text(docs[0].page_content)\n",
    "docs = [Document(page_content=c) for c in chunks]\n",
    "\n",
    "print(\"생성된 청크 개수:\", len(docs))\n",
    "for i, d in enumerate(docs):\n",
    "    print(f\"청크 {i} 길이:\", len(d.page_content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0c710d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d33f9469",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_summaries = map_chain.batch(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8e2fd50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2cd1ced3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- RAG(Retrieval-Augmented Generation)는 GPT 모델의 한계를 극복하고 응답 정확도를 향상시키기 위한 기술로, 최신 정보와 신뢰할 수 있는 외부 데이터를 활용한다.\n",
      "- RAG는 ChatGPT의 최신 정보 부족, 내부 데이터 미학습, 보안 문제, 할루시네이션 현상 등의 문제를 해결할 수 있는 방법론이다.\n",
      "- RAG를 통해 사용자는 개인 맞춤형 챗봇이나 특정 도메인에 최적화된 챗봇을 자유롭게 생성할 수 있다.\n",
      "- RAG는 GPT가 사전 학습된 지식에 의존하지 않고, 제공된 자료를 바탕으로 더 정확한 답변을 생성할 수 있도록 돕는다.\n",
      "- ChatGPT의 내장 RAG 시스템은 사용자가 문서를 업로드하고 질문할 때 그럴듯한 답변을 제공하지만, 그 정보의 정확성을 확인하기는 어렵다.\n",
      "==================================================\n",
      "- 한국개발연구원(KDI)에서 발간한 2023년 하반기 경제전망 보고서는 국내외 경제 동향을 분석하고 중단기 경제 전망을 제공하여 정부와 기업의 정책 수립에 도움을 주기 위해 작성되었다.\n",
      "- 보고서는 고금리 기조, 수출 회복세, 내수 둔화 등 현재의 경제 상황과 2024년의 완만한 경제 회복 전망을 다룬다.\n",
      "- 또한, 국제유가 변동과 중국 경제 상황 변화 등 대외 불확실성을 위험 요인으로 지적하며 이에 대한 대응 방안을 모색한다.\n",
      "- ChatGPT는 문서의 구체적인 내용을 제공하지 못하는 경우가 발생하며, 이는 사용자가 질문을 구체화할수록 할루시네이션이 발생할 수 있음을 보여준다.\n",
      "- RAG 시스템은 최신 정보를 기반으로 답변을 제공하고, 그 과정의 투명성을 높여 사용자가 답변의 정확성을 확인할 수 있도록 돕는다.\n",
      "==================================================\n",
      "- LangSmith와 RAG 시스템을 통해 LLM의 답변 추적 과정을 심도 있게 분석하고 개선할 수 있다.\n",
      "- RAG는 LLM의 할루시네이션을 감소시키는 데 효과적이며, 유효한 정보만을 기반으로 답변을 도출하도록 돕는다.\n",
      "- LangChain은 대규모 언어 모델을 활용한 애플리케이션 개발을 용이하게 하며, 다양한 서비스에 GPT를 접목할 수 있는 도구이다.\n",
      "- RAG 시스템의 전체 프로세스를 LangChain을 통해 투명하게 구현하고 튜닝하여 비즈니스 환경에서도 활용 가능한 성능을 달성할 수 있다.\n",
      "- RAG 프로세스는 사용자의 질문에 대해 관련 정보를 데이터베이스에서 검색하여 LLM이 보다 정확한 답변을 생성하도록 돕는 구조로 되어 있다.\n",
      "==================================================\n",
      "- 데이터 소스를 벡터 스토어로 사용하여 문서 로드, 텍스트 분할, 임베딩, 저장의 네 단계를 통해 정보를 처리하는 과정이 설명된다.\n",
      "- 각 단계에서 문서를 청크로 나누고, 이를 임베딩하여 벡터 형태로 변환함으로써 컴퓨터가 문서의 내용을 이해할 수 있도록 한다.\n",
      "- 사용자 질문에 대해 유사도 계산을 통해 가장 관련성이 높은 청크를 찾아내는 과정이 포함된다.\n",
      "- RAG 프로세스의 실행 단계에서는 질문에 맞는 벡터를 검색하고, 이를 바탕으로 언어 모델이 답변을 생성하는 일련의 과정을 설명한다.\n",
      "- 최종적으로 모든 과정을 하나의 파이프라인으로 묶는 체인 생성이 이루어진다.\n",
      "==================================================\n",
      "- 리트리버 단계는 사용자 질문을 벡터로 변환하고, 이를 통해 관련 문서를 검색하는 핵심 과정이다.\n",
      "- 프롬프트 단계에서는 검색된 문서들을 바탕으로 언어 모델이 사용할 질문이나 명령을 생성한다.\n",
      "- LLM 단계에서는 구성된 프롬프트를 입력으로 받아 대규모 언어 모델을 통해 사용자 질문에 대한 응답을 생성한다.\n",
      "- 체인 생성 단계는 앞서 설명한 일곱 단계를 하나로 묶어 완전한 RAG 파이프라인으로 조립하는 과정이다.\n",
      "- RAG를 활용한 프롬프트 최적화와 파인 튜닝을 통해 모델의 성능을 극대화할 수 있다.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for doc in doc_summaries:\n",
    "    print(doc)\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fea305",
   "metadata": {},
   "source": [
    "### Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8d8cf6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a professional summarizer. You are given a list of summaries of documents and you are asked to create a single summary of the documents.\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "#Instructions: \n",
      "1. Extract main points from a list of summaries of documents\n",
      "2. Make final summaries in bullet points format.\n",
      "3. Answer should be written in \u001b[33;1m\u001b[1;3m{language}\u001b[0m.\n",
      "\n",
      "#Format: \n",
      "- summary 1\n",
      "- summary 2\n",
      "- summary 3\n",
      "- ...\n",
      "\n",
      "Here is a list of summaries of documents: \n",
      "\u001b[33;1m\u001b[1;3m{doc_summaries}\u001b[0m\n",
      "\n",
      "#SUMMARY:\n"
     ]
    }
   ],
   "source": [
    "# reduce prompt 다운로드\n",
    "reduce_prompt = hub.pull(\"teddynote/reduce-prompt\")\n",
    "\n",
    "# 프롬프트 출력\n",
    "reduce_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "52cf3d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_chain = reduce_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25244e97",
   "metadata": {},
   "source": [
    "부분요약을 모아서 전체요약으로 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e7a36785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- RAG(Retrieval-Augmented Generation)는 GPT 모델의 한계를 극복하고 응답 정확도를 향상시키기 위한 기술로, 최신 정보와 신뢰할 수 있는 외부 데이터를 활용한다.\n",
      "- RAG는 ChatGPT의 최신 정보 부족, 내부 데이터 미학습, 보안 문제, 할루시네이션 현상 등의 문제를 해결할 수 있는 방법론이다.\n",
      "- 사용자는 RAG를 통해 개인 맞춤형 챗봇이나 특정 도메인에 최적화된 챗봇을 생성할 수 있다.\n",
      "- RAG는 GPT가 사전 학습된 지식에 의존하지 않고, 제공된 자료를 바탕으로 더 정확한 답변을 생성하도록 돕는다.\n",
      "- 한국개발연구원(KDI)의 경제전망 보고서는 고금리 기조, 수출 회복세, 내수 둔화 등 현재의 경제 상황과 2024년의 완만한 경제 회복 전망을 다룬다.\n",
      "- RAG 시스템은 최신 정보를 기반으로 답변을 제공하고, 그 과정의 투명성을 높여 사용자가 답변의 정확성을 확인할 수 있도록 돕는다.\n",
      "- LangChain은 대규모 언어 모델을 활용한 애플리케이션 개발을 용이하게 하며, RAG 프로세스를 통해 비즈니스 환경에서도 활용 가능한 성능을 달성할 수 있다.\n",
      "- RAG 프로세스는 사용자의 질문에 대해 관련 정보를 데이터베이스에서 검색하여 LLM이 보다 정확한 답변을 생성하도록 돕는 구조로 되어 있다.\n",
      "- RAG의 실행 단계는 질문에 맞는 벡터를 검색하고, 이를 바탕으로 언어 모델이 답변을 생성하는 일련의 과정을 포함한다.\n",
      "- RAG를 활용한 프롬프트 최적화와 파인 튜닝을 통해 모델의 성능을 극대화할 수 있다."
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.messages import stream_response\n",
    "\n",
    "answer = reduce_chain.stream(\n",
    "    {\"doc_summaries\": \"\\n\".join(doc_summaries), \"language\": \"Korean\"}\n",
    ")\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2716c96c",
   "metadata": {},
   "source": [
    "하나의 체인에 묶어서 실행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9461d7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain\n",
    "\n",
    "\n",
    "@chain\n",
    "def map_reduce_chain(docs):\n",
    "    map_llm = ChatOpenAI(\n",
    "        temperature=0,\n",
    "        model_name=\"gpt-4o-mini\",\n",
    "    )\n",
    "\n",
    "    # map prompt 다운로드\n",
    "    map_prompt = hub.pull(\"teddynote/map-prompt\")\n",
    "\n",
    "    # map chain 생성\n",
    "    map_chain = map_prompt | map_llm | StrOutputParser()\n",
    "\n",
    "    # 첫 번째 프롬프트, ChatOpenAI, 문자열 출력 파서를 연결하여 체인을 생성합니다.\n",
    "    doc_summaries = map_chain.batch(docs)\n",
    "\n",
    "    # reduce prompt 다운로드\n",
    "    reduce_prompt = hub.pull(\"teddynote/reduce-prompt\")\n",
    "    reduce_llm = ChatOpenAI(\n",
    "        model_name=\"gpt-4o\",\n",
    "        temperature=0,\n",
    "        callbacks=[StreamingCallback()],\n",
    "        streaming=True,\n",
    "    )\n",
    "\n",
    "    reduce_chain = reduce_prompt | reduce_llm | StrOutputParser()\n",
    "\n",
    "    return reduce_chain.invoke(\n",
    "        {\"doc_summaries\": \"\\n\".join(doc_summaries), \"language\": \"Korean\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "000307fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- RAG(Retrieval-Augmented Generation)는 GPT 모델의 한계를 극복하고 응답 정확도를 향상시키기 위한 기술로, 최신 정보와 신뢰할 수 있는 외부 데이터를 활용한다.\n",
      "- RAG는 ChatGPT의 최신 정보 부족, 내부 데이터 미비, 보안 문제, 할루시네이션 현상 등의 문제를 해결할 수 있는 방법론이다.\n",
      "- RAG를 통해 사용자는 개인 맞춤형 챗봇이나 특정 도메인에 최적화된 챗봇을 생성할 수 있으며, GPT가 사전 학습된 지식에 의존하지 않고 더 정확한 답변을 생성할 수 있도록 돕는다.\n",
      "- RAG 시스템은 최신 정보를 기반으로 답변을 제공하고, 그 과정의 투명성을 높여 사용자가 답변의 정확성을 확인할 수 있도록 돕는다.\n",
      "- LangSmith와 RAG 시스템을 통해 LLM의 답변 추적 과정을 심도 있게 분석하고 개선할 수 있으며, RAG는 LLM의 할루시네이션을 감소시키는 데 효과적이다.\n",
      "- LangChain은 대규모 언어 모델을 활용한 애플리케이션 개발을 용이하게 하며, 다양한 서비스에 GPT를 접목할 수 있는 도구이다.\n",
      "- RAG 프로세스는 사용자의 질문에 대해 관련 정보를 데이터베이스에서 검색하여 LLM이 보다 정확한 답변을 생성하도록 돕는 구조로 되어 있다.\n",
      "- 데이터 소스를 벡터 스토어로 사용하여 문서 로드, 텍스트 분할, 임베딩, 저장의 네 단계를 통해 정보를 처리하는 과정이 설명된다.\n",
      "- RAG를 활용한 프롬프트 최적화와 파인 튜닝을 통해 모델의 성능을 극대화하고, 정확도를 98%까지 향상시킬 수 있다.\n",
      "- 한국개발연구원(KDI)의 2023년 하반기 경제전망 보고서는 국내외 경제 동향을 분석하고 중단기 경제 전망을 제공하여 정부와 기업의 정책 수립에 도움을 주기 위해 작성되었다.\n",
      "- 보고서는 고금리 기조, 수출 회복세, 내수 둔화 등 현재의 경제 상황과 2024년의 완만한 경제 회복 전망을 다루며, 국제유가 변동과 중국 경제 상황 변화 등 대외 불확실성을 위험 요인으로 지적한다."
     ]
    }
   ],
   "source": [
    "answer = map_reduce_chain.invoke(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2c212c",
   "metadata": {},
   "source": [
    "## Map-Refine\n",
    "\n",
    "청크로 나눈 후 첫번째 청크를 요약 -> 요약된 문장과 두번째 청크를 합쳐서 요약 -> 요약된 문장과 세번재 청크를 합쳐서 요약 -> ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7449bbcb",
   "metadata": {},
   "source": [
    "### Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "30c73143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are an expert summarizer. Your task is to summarize the following document in \u001b[33;1m\u001b[1;3m{language}\u001b[0m.\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Extract most important main thesis from the documents, then summarize in bullet points.\n",
      "\n",
      "#Format:\n",
      "- summary 1\n",
      "- summary 2\n",
      "- summary 3\n",
      "-...\n",
      "\n",
      "Here is a given document: \n",
      "\u001b[33;1m\u001b[1;3m{documents}\u001b[0m\n",
      "\n",
      "Write 1~5 sentences. Think step by step.\n",
      "#Summary:\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# map llm 생성\n",
    "map_llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model_name=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "# map chain 생성\n",
    "map_summary = hub.pull(\"teddynote/map-summary-prompt\")\n",
    "\n",
    "# 프롬프트 출력\n",
    "map_summary.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "58c1b036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map chain 생성\n",
    "map_chain = map_summary | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "faf07a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- RAG(Retrieval-Augmented Generation)는 GPT 모델의 한계를 극복하기 위해 최신 정보와 신뢰할 수 있는 외부 데이터를 활용하여 응답 정확도를 향상시키는 기술이다.\n",
      "- RAG는 사용자가 원하는 대로 데이터베이스와 모델을 커스터마이즈할 수 있어 특정 도메인에 특화된 챗봇 제작에 유용하다.\n",
      "- RAG를 통해 최신 정보 기반의 답변 제공, 내부 데이터 활용, 할루시네이션 현상 감소 등의 문제를 해결할 수 있다.\n",
      "- RAG는 GPT에 정보 검색 기능을 추가하여 사전 학습된 지식에 의존하지 않고 정확한 답변을 생성할 수 있도록 한다.\n",
      "- ChatGPT의 내장 RAG 시스템은 사용자가 문서를 업로드하고 질문할 때 그럴듯한 답변을 제공하지만, 정보의 정확성을 확인하기 어려운 단점이 있다.\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 문서의 요약 출력\n",
    "print(map_chain.invoke({\"documents\": docs[0], \"language\": \"Korean\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b994e0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 문서를 입력으로 정의합니다.\n",
    "input_doc = [{\"documents\": doc, \"language\": \"Korean\"} for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c062a492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'documents': Document(metadata={}, page_content='CHAPTER\\n01 RAG 이해하기\\n\\n학습 목표\\nRAG(Retrieval-Augmented Generation)는 문서 로드, 검색, 답변 생성의 투명한 과정을 통해 할루시네이션 현상을 줄이고, 최신 정보와 신뢰할 수 있는 외부 데이터를 활용해 응답 정확도를 대폭 향상시킴으로써 GPT 모델의 한계를 극복하기 위한 기술입니다. RAG는 프롬프트 엔지니어링이나 파인 튜닝보다 구현이 용이하여 실용적이며, 사용자가 원하는 대로 데이터베이스와 모델을 커스터마이즈할 수 있어 특정 도메인에 특화된 챗봇을 제작할 수 있는 강력한 도구입니다. 그러한 RAG를 사용해야 하는 이유에 관해 알아보겠습니다.\\n\\n(01) RAG를 사용해야 하는 이유\\nChatGPT는 2022년 11월 등장하자마자 순식간에 많은 사용자를 확보했습니다. 2023년 11월에는 GPTs 스토어가 출시되어 GPT의 기능을 플러그인으로 제작하고 배포할 수 있게 되었고, 여러 고급 기능이 보완되면서 사용자들은 단순히 질문하고 답변받는 것에서 더 나아가 전문적인 영역까지 ChatGPT를 적극적으로 활용하기 시작했습니다. 이러한 과정에서 점차 다음과 같은 문제점들이 드러나기 시작했습니다.\\n\\n1. ChatGPT는 최신 정보가 학습되어 있지 않습니다.\\n2. 개인이나 회사의 내부 데이터가 학습되어 있지 않아, 특정 도메인(개인 정보, 회사 내부 정보)에 대한 질문에는 기대하는 답변을 얻을 수 없습니다.\\n3. ChatGPT에 개인이나 회사 정보를 담은 문서를 업로드하면 보안상 문제가 될 수 있습니다.\\n4. 문서의 양이 많아질수록 할루시네이션 현상이 발생하기 쉽습니다.\\n\\nChatGPT의 한계를 보완하기 위해 주목받은 RAG\\nRAG는 ChatGPT의 한계를 보완하기 위해 주목받기 시작한 기술입니다. RAG란 Retrieval-Augmented Generation의 줄임말로, 검색(Retrieval), 증강(Augmented), 생성(Generation)이라는 의미를 담고 있으며, 거대 언어 모델(LLM; Large Language Model)이 외부의 신뢰할 수 있는 지식 데이터베이스를 참조하여 최적화된 응답을 생성하는 기술입니다.\\n\\nRAG의 다양한 방법론을 활용하여 지속적으로 업그레이드하면 ChatGPT만 사용했을 때 50점 수준이었던 답변의 품질을 80점, 90점대로 끌어올릴 수 있습니다. 적절한 RAG를 적용하면 앞서 언급된 문제점들을 다음과 같이 개선할 수 있습니다.\\n\\n1. 최신 정보를 기반으로 답변할 수 있으며, LLM이 정보를 찾을 수 없는 경우 \\'검색\\' 기능을 활용해 답변을 제공할 수 있습니다.\\n2. 회사 내부에 데이터베이스를 구현함으로써 개인이나 회사의 내부 데이터를 참고하여 GPT가 답변할 수 있습니다.\\n3. 문서를 내부 데이터베이스에 저장하고 지속적으로 데이터를 축적할 수 있으며, 저장된 데이터베이스에서 원하는 정보를 검색한 후 이를 바탕으로 답변을 생성할 수 있습니다.\\n4. 저장된 데이터베이스에서 답변의 출처를 역으로 검색하고 검증하는 방식으로 할루시네이션 현상을 줄일 수 있습니다.\\n\\n따라서 RAG를 사용하면 GPT가 사전 학습한 내용뿐 아니라 새롭게 축적되는 데이터베이스를 기반으로도 답변할 수 있어, 사용자는 데이터베이스만 업데이트하면 더 높은 품질의 최신 답변을 얻을 수 있습니다. 결과적으로 개인 맞춤형 챗봇이나 회사 내부 데이터에 특화된 챗봇과 같이 특정 도메인에 최적화된 챗봇을 자유롭게 생성할 수 있습니다.\\n\\n이해를 돕기 위해 예시를 들어 보겠습니다. RAG를 사용하기 전 ChatGPT에게 다음과 같이 질문해 보았습니다.\\n“서울특별시에 사는 테디 아버지 이름이 뭐야?\"\\nChatGPT는 이러한 개인적인 질문을 받으면 굉장히 황당할 겁니다. 테디가 누구인지, 그의 아버지 이름이 뭔지 어떻게 알겠냐고요. 이런 경우 모른다고 답하거나 답변하는 과정에서 잘못된 정보를 생성(할루시네이션)할 가능성이 높습니다. 하지만 다음과 같은 가족관계증명서를 GPT에게 주면 어떻게 될까요? GPT는 자료를 참고해서 테디 아버지 이름은 \\'폴\\'이라고 정확한 답변을 제공할 수 있을 것입니다.\\n\\n이처럼 RAG는 GPT가 사전 학습된 지식에만 의존하지 않고 참고할 만한 자료를 주면 그것을 토대로 답변하기 때문에 훨씬 더 정확합니다. 쉽게 말해 사전 학습된 GPT에 정보 검색 기능을 추가한 것이죠. 검색 대상은 문서와 인터넷은 물론 다양한 도메인일 수도 있습니다.\\n\\n따라서 우리가 할 일은 이러한 다양한 정보 검색 기술을 활용해서 RAG 시스템을 점점 고도화하는 것입니다. RAG가 발전할수록 답변의 정교함도 높아집니다. 예를 들어 관련된 모든 문서를 GPT에 제공하는 대신 핵심 정보만 요약해서 전달하면 훨씬 더 효율적으로 참고할 수 있겠죠. 이처럼 GPT가 참고할 데이터를 잘 정제하면 RAG 시스템의 성능을 높일 수 있습니다.\\n\\n커스터마이즈가 어려운 ChatGPT 내장 RAG 시스템\\nChatGPT를 어느 정도 사용해 본 사용자라면 자신도 모르게 RAG를 경험해 봤을 것입니다. 다음과 같이 ChatGPT에 문서를 업로드하고 질문하면 이를 기반으로 그럴듯한 답변을 제공하는데, 이는 ChatGPT에 내장된 자체 RAG 시스템 때문입니다. 하지만 이렇게 생성된 답변이 실제로 정확한 정보인지 확인하기는 어렵습니다.\\n\\n다음과 같이 한국 경제 전망에 대한 보고서 PDF 문서를 ChatGPT에 업로드하고, 특정 내용을 알려 달라고 요청해 보겠습니다. 보고서의 주요 내용을 그럴듯하게 답변하는데, 이 답변이 정말 해당 보고서에서 가져온 내용인지, 아니면 ChatGPT가 학습한 내용으로 적당히 둘러댄 답변인지 어떻게 분간할 수 있을까요?'),\n",
       "  'language': 'Korean'},\n",
       " {'documents': Document(metadata={}, page_content='다음과 같이 한국 경제 전망에 대한 보고서 PDF 문서를 ChatGPT에 업로드하고, 특정 내용을 알려 달라고 요청해 보겠습니다. 보고서의 주요 내용을 그럴듯하게 답변하는데, 이 답변이 정말 해당 보고서에서 가져온 내용인지, 아니면 ChatGPT가 학습한 내용으로 적당히 둘러댄 답변인지 어떻게 분간할 수 있을까요?\\n\\n이 문서는 한국개발연구원(KDI)에서 발간한 2023년 하반기 경제전망 보고서입니다. 이 보고서는 국내외 경제 동향을 분석하고 중단기 경제 전망을 제공하며, 경제 전망에 대한 불확실성 요인과 대책을 연구하여 정부의 경제 정책 수립과 기업의 경영, 학계의 연구 활동에 도움을 주기 위해 작성되었습니다.\\n보고서의 주요 내용은 다음과 같습니다:\\n1. 현재의 경제 상황과 내년의 경제 전망을 다루며, 고금리 기조의 영향, 수출 회복세, 내수 둔화, 물가 상황, 취업자 수 변화 등에 대해 다룹니다.\\n2. 2024년 국내경제 전망에서는 완만한 회복세를 예측하며, 성장률, 소비자 물가, 취업자 수, 경상수지 등 다양한 경제 지표에 대해 예측합니다.\\n3. 재정정책, 통화정책, 금융정책 등의 정책 방향을 제시합니다.\\n4. 위험 요인으로는 국제유가 변동, 중국의 경제 상황 변화 등 대외 불확실성이 높은 점을 지적하며, 이에 대한 대응 방안을 모색합니다.\\n이 보고서는 정부 및 기업의 정책 결정에 중요한 정보를 제공하며, 경제 상황에 대한 깊은 이해와 미래 전망에 대한 지침을 담고 있습니다.\\n\\n문서 내용에 대해 더 자세히 알아보고자 세부 내용을 선택하여 다시 질문하고, 반드시 문서의 내용을 바탕으로 답변해 달라고 요청했습니다. 그러나 ChatGPT는 해당 내용에 대한 구체적인 데이터를 제공하지 않는다는 이상한 답변을 내놓았습니다. 문서에 분명히 해당 내용이 있음에 도 ChatGPT가 관련 정보를 찾지 못하는 현상이 발생했습니다.\\n보고서에서는 유로존의 전체 및 청년 실업률에 대한 구체적인 데이터를 제공하지 않습니다. 이 문서는 한국의 경제 상황과 전망에 초점을 맞추고 있어, 유로존의 실업률과 같은 특정 국제 경제 지표에 대한 세부 수치는 포함되어 있지 않습니다. 유로존의 실업률 정보가 필요하시다면, 유럽연합 통계국(Eurostat)의 공식 웹사이트에서 최신 데이터를 찾으실 수 있을 것입니다.\\n\\n일반적으로 ChatGPT에 문서를 입력하고 질문하면 답변이 잘 나온다고 생각하지만, 실제로는 조금만 더 구체적으로 질문하면 문서의 내용과 전혀 다른 답변이 나오는 할루시네네이션이 발생하기도 합니다.\\n\\nII. 세계경제 동향\\n실업률이 낮은 수준을 지속하는 등 노동시장 관련 지표는 양호한 흐름을 유지\\n- 3/4분기 유로존의 전체 및 청년실업률은 전분기에 이어 각각 6.5%, 14.0%의 낮은 수준을 기록\\n- 2/4분기 임금상승률이 높은 수준을 지속하는 가운데, 장기실업자 비중은 하향 안정세를 유지\\n\\nChatGPT에서 RAG가 작동하는 과정은 OpenAI에서 공개하고 있지 않아 사용자가 이를 직접 제어할 수는 없습니다. 따라서 문서를 ChatGPT가 최대한 잘 검색할 수 있는 형태로 변경하는 것이 현재로서는 최선의 방법입니다. 예를 들어 자주 하는 질문을 FAQ로 만들거나 PDF, DOCX, HWP 등의 문서를 마크다운 형식으로 작성하는 방식이 있습니다. 하지만 모든 문서를 이렇게 변경하는 것은 많은 시간과 노력이 필요한 작업이라 현실적으로 어렵습니다. 이러한 한계를 극복하기 위해 우리는 LangChain을 이용해 RAG 시스템을 직접 구축해 볼 것입니다.\\n\\n(02) RAG의 기막힌 능력\\nRAG는 장점이 큰 기술이지만 LLM을 처음 접하는 사람들이 RAG 도입을 주저하는 이유는 주로 복잡해 보이는 용어와 기술적 장벽 때문인 것 같습니다. 그러나 기본 원리만 이해한다면 RAG는 생각보다 어려운 기술이 아닙니다.\\n\\n플러그인처럼 교체하는 방식의 쉬운 구현\\n다음은 언어 모델의 성능 향상을 위한 각 기술의 난이도를 비교한 그래프입니다. 가장 오른쪽에 있는 완전 파인 튜닝(Full Fine-Tuning)은 다소 전문적인 영역이기 때문에 개인이 수행하기에는 어려울 수 있습니다. PEFT(Parameter-Efficient Fine-Tuning) 역시 파인 튜닝의 한 종류이지만, 충분한 시간과 노력을 들인다면 개인적으로 시도해 볼 수 있는 수준입니다.\\nRAG는 코드 작성이 필요 없는 프롬프트 엔지니어링과 비교해도 구현 난이도가 그리 높지 않은데, 이는 앞으로 학습할 8단계의 세부 모듈을 플러그인처럼 교체하는 방식으로 구현할 수 있기 때문입니다.\\n\\n최신 정보를 기반으로 답변\\n그래프를 보면 RAG가 최신 정보에 대한 답변에서도 월등히 뛰어난 성능을 보여 주고 있습니다. 이는 사용자가 직접 원하는 최신의 문서를 데이터베이스에 넣어 업데이트할 수 있기 때문입니다.\\n\\n답변 과정을 투명하게 확인 및 해석 가능\\nRAG는 전 과정을 모니터링하고 추적할 수 있으며, 각 단계를 상세히 분석하고 조정할 수 있습니다. 이는 모든 과정을 사용자가 직접 설계하기 때문에 답변을 해석하는 과정에서도 잘 나온 답변은 왜 잘 나왔는지, 제대로 된 답변을 얻지 못했다면 그 이유는 무엇인지를 직접 확인할 수 있기 때문입니다. 다음 그래프에서도 볼 수 있듯이, RAG는 답변의 투명성과 해석 능력 측면에서 압도적인 성능을 보여 주고 있습니다.'),\n",
       "  'language': 'Korean'},\n",
       " {'documents': Document(metadata={}, page_content='실제 예시를 통해 답변 추적 과정을 확인해 보겠습니다. LLM의 동작 과정을 추적하는 도구인 LangSmith에서 \\'삼성전자에서 자체 개발한 AI의 이름은?\\'이라고 질문을 던지면 왼쪽 추적 과정에서 답변 도출까지의 세부 과정, 소요 시간, 토큰 수 등을 확인할 수 있습니다. 이는 간단한 예시이지만, 추후 더 복잡한 설계를 진행한다고 해도 이러한 과정을 더욱 심도 있게 분석할 수 있습니다.\\n실제로 Retriever를 클릭하면 질문(query)이 입력되었을 때 어떤 문서(DOCUMENTS)의 어느 구절에서 관련 내용을 검색했는지를 다음과 같이 상세하게 확인할 수 있습니다.\\n또한 해당 문서들을 각각 클릭해서 열어 보면 실제 텍스트 내용까지도 확인할 수 있습니다. 이렇게 세부 과정을 확인하면 답변이 잘 나오지 않았을 경우 그 원인을 추적하여 결과를 개선할 수 있습니다.\\n\\n할루시네이션 감소\\nRAG는 LLM의 대표적 부작용인 할루시네이션을 감소시키는 데도 효과적입니다. 유효한 정보만을 기반으로 답변을 도출하도록 강제하거나, 주어진 문서에서만 답변의 출처를 찾도록 하는 방식으로 오류를 줄일 수 있기 때문입니다. 다음 그래프를 보면 할루시네이션 방지에 있어 RAG가 가장 큰 영향을 미치는 것을 확인할 수 있습니다.\\n\\n(03) LangChain을 이용한 RAG 시스템 구축\\nLangChain(랭체인)은 대규모 언어 모델로 구동되는 애플리케이션을 개발하기 위한 프레임워크입니다. 즉, GPT와 같은 언어 모델과 우리가 만들고자 하는 서비스나 프로세스를 쉽게 연결해 주는 도구입니다.\\n\\nChatGPT는 GPT라는 언어 모델을 기반으로 한 대화형 AI 플랫폼입니다. 우리는 이 똑똑한 GPT를 채팅만 하는 데 그치지 않고, 다양한 서비스에 활용합니다. 예를 들면 여행 서비스를 운영하는 경우 GPT로 자동 여행 계획을 세워 주는 서비스를 만들거나, 차량 렌트 서비스를 운영하는 경우 GPT로 고객 응대 챗봇을 만듭니다. 이렇게 똑똑한 GPT의 두뇌를 원하는 작업 흐름에 접목하여 체인으로 엮는 형태로 만드는 것이 바로 LangChain입니다.\\n\\nGPT로 어떤 문서에 기반한 Q&A 시스템을 만들려면 문서를 그냥 넣기만 해서는 안 되고, 문서 안에 있는 텍스트를 읽어들일 수 있게끔 별도로 작업을 해 주어야 하는데, LangChain으로는 이런 작업을 너무 쉽게 할 수 있습니다. 또한 어떤 동작을 파이썬 코드로 처음부터 끝까지 작성하려면 시간이 굉장히 오래 걸리지만, LangChain에서는 코드 한두 줄로 편리하게 구현할 수 있습니다.\\n\\n일단 LangChain만 배워 두면 어떤 데이터베이스를 쓸지, 어떤 임베더(텍스트 같은 정보를 연산 가능한 수치로 변환해 주는 도구)를 쓸지, 어떤 종류의 문서를 업로드할지 등만 결정해서 가져다 쓰면 되니 데이터베이스 전문 개발사들도 LangChain을 도입하기 위해 노력하고 있고, LangChain을 도입하는 분야와 그 산업의 크기는 점점 더 커지고 있습니다.\\n\\nLLM을 이용해 서비스를 개발한다고 하면 LangSmith, LangGraph, LangServe 등의 도구도 필요합니다. 이 모든 것을 통합한 LangChain 생태계를 앞으로 하나하나 구현해 보겠습니다.\\n\\nLangChain으로 구현할 RAG 시스템 전체 프로세스\\nChatGPT는 자체 RAG 시스템을 통해 답변을 제공하지만, 더 나은 답변을 위해 세부 알고리즘을 조정할 수 없다는 문제가 있습니다. 이제 우리는 LangChain을 통해 RAG의 모든 세부 프로세스를 한 땀 한 땀 구현할 것입니다. 한마디로 \\'튜닝\\'을 하는 것이죠. 우리가 원하는 형태의 답변을 얻을 때까지 각 과정을 투명하게 개선하고, 그 방법론을 체계적으로 정립해 놓으면 다양한 비즈니스 환경에서도 얼마든지 활용 가능한 수준의 성능에 도달할 수 있습니다.\\n다음은 RAG 시스템의 전체 프로세스입니다. 이 그림이 처음에는 복잡해 보일 수 있지만, 각 세부 과정을 하나씩 익혀 나가면 어렵지 않게 이해할 수 있습니다.\\n\\nRAG 프로세스의 사전 단계 이해하기\\nRAG를 쓰는 목적을 이해하기 위해 GPT로 질문을 해서 답변을 받는 과정을 살펴봅시다. 먼저 사용자가 GPT에 “삼성전자가 신규 개발한 AI가 뭐야?\" 같은 질문을 입력합니다. 사용자의 질문이 프롬프트에 들어오면 LLM에 전달되어 답변을 출력합니다. 이때 GPT는 아무런 참고할 만한 정보를 따로 받지 않았기 때문에 사전 학습된 내용만으로 답변을 줄 수밖에 없습니다. 만약 GPT가 현재 상황과 다른 오래된 정보만 알고 있다면 답변에서 할루시네이션이 일어나기 십상입니다.\\n\\n반면 RAG에서는 미리 참고할 정보(가령 PDF, CSV 등)를 데이터베이스나 문서 형태로 저장해 둡니다. 사용자가 질문을 입력하면 리트리버(retriever)가 해당 질문과 유사성이 높은 문서를 데이터베이스에서 찾아 반환하고, 이를 프롬프트에 포함하여 LLM이 컨텍스트(context)에서 필요한 내용을 검색해서 답변을 생성하도록 돕습니다.\\n\\n그렇다면 참고할 정보를 어떻게 가져올까요? 가령 \\'인공지능 산업의 최신 동향\\'이라는 23페이지 분량의 보고서 PDF 파일을 업로드했다고 가정해 보겠습니다. 만약 프롬프트에서 이 파일의 모든 정보를 한 번에 참고한다면, 사용자가 질문을 할 때마다 23페이지나 되는 내용이 모두 프롬프트 입력으로 들어가 버립니다. 그러면 질문을 처리하는 비용이 비싸지기도 하거니와 GPT에 너무 많은 정보를 제공한 탓에 중요한 정보를 찾지 못할 수도 있습니다. 그래서 업로드한 정보에서 관련성 있는 정보만 골라서 리트리버(retriever, 검색기)에 전달하는 것이 효율적입니다. 이 과정이 RAG 프로세스의 사전 단계에 해당합니다.'),\n",
       "  'language': 'Korean'},\n",
       " {'documents': Document(metadata={}, page_content=\"사전 단계에서는 데이터 소스를 벡터 스토어로 사용하여 문서 로드-텍스트 분할-임베딩-저장이라는 네 단계를 진행합니다.\\n- 1단계 | 문서 로드(Document Load): 외부 데이터 소스에서 필요한 문서를 불러와서 초기 처리를 합니다. 이것은 마치 학생이 공부하기 전에 책장에서 필요한 책을 여러 권 챙겨 오는 과정과 같습니다.\\n- 2단계 | 텍스트 분할(Text Split): 로드된 문서를 처리 가능한 작은 단위인 청크(chunk)로 분할합니다. 두꺼운 책을 주제별로 나누어 Part나 Chapter로 구분하는 것과 유사합니다.\\n- 3단계 | 임베딩(Embedding): 분할된 청크를 벡터 형태로 변환하여 문서의 의미를 수치화합니다. 자연어를 컴퓨터가 이해할 수 있는 수치로 변경하는 과정입니다.\\n- 4단계 | 벡터 스토어 저장: 임베딩된 청크를 데이터베이스에 저장합니다. 임베딩된 벡터들을 데이터베이스에 저장합니다. 이는 요약된 키워드를 색인으로 뽑아서 나중에 빠르게 찾을 수 있게 정리해 두는 과정입니다.\\n\\n먼저 문서 로드 단계에서는 PDF, 엑셀, 논문, 이미지, 데이터베이스 등 문서를 로드합니다. 가령 PDF 파일을 로드하면 그 안에 있는 텍스트를 긁어 오는 작업을 합니다.\\n그다음은 텍스트 분할입니다. '삼성전자가 신규 개발한 AI가 뭐야?'라는 질문에 답하려면 '인공지능 산업의 최신 동향' 보고서 PDF에서 18페이지의 일부 내용만 가져와서 답변하면 됩니다. 이처럼 전체 정보를 다 프롬프트에 쓰지 않고, 청크라는 단위로 내용을 분할합니다. 토큰 수를 기준으로 청크 크기를 지정하면, 해당 분량의 청크로 분할됩니다. 가령 청크 크기를 1,000토큰으로 잡고, 한 페이지에 청크가 세 개 정도 들어간다고 가정해 보겠습니다. 그러면 23페이지의 보고서 내용이 69개의 청크로 분할되어 저장됩니다.\\n사용자 질문이 들어오면 질문의 내용과 각각의 청크에 대해 유사도 계산을 해서 가장 관련성이 높은 청크를 뽑아내는 작업을 합니다. 유사도를 계산하기 위해 각 청크의 값을 수학적인 표현으로 바꿔야 하는데 이것을 임베딩이라고 합니다. 자연어는 복잡하고 다양한 의미를 내포하고 있는데, 임베딩을 통해 텍스트를 정량화된 숫자 값으로 변환하면 컴퓨터가 문서의 내용과 의미를 더 잘 이해해서 처리할 수 있습니다.\\n쉬운 예를 들어 임베딩을 설명해 보겠습니다. '매운맛', '신맛', '단맛'이라는 정보를 임베딩해서 각각 0.1, 0.7, 0.9와 같은 값을 매깁니다. 그러면 사용자가 '새콤달달한 맛'이라는 정보를 입력하면, '신맛'과 '단맛' 사이의 중간 지점인 0.8이라는 값을 매길 수 있습니다. 이렇게 되면 '새콤달달한 맛'에 대해 질문이 들어 왔을 때 이미 주어진 정보에는 이와 정확히 일치하는 표현이 없더라도 '신맛'이나 '단맛'에 대한 청크가 질문과 유사도가 높다고 판단할 수 있습니다.\\n\\n'인공지능 산업의 최신 동향' 같은 복잡하고 풍부한 텍스트의 정보는 하나의 숫자 표현으로 나타낼 수 없습니다. 그래서 여러 숫자의 좌표 집합인 벡터(vector)로 표현합니다. 우리가 사용할 OpenAI의 임베딩의 벡터는 1536차원입니다. 이 말은, 한 단어든 문장이든 단락이든 이를 나타내는 벡터 값에 1,536개의 숫자가 들어간다는 뜻입니다. 알고리즘에 따라 임베딩한 벡터 값의 개수가 달라지는데, 표현이 풍부할수록 정교하게 유사도를 비교할 수 있겠지만 그 대신 리소스를 더 많이 소모합니다.\\n앞서 청크 크기를 기준으로 정보를 몇 개의 토큰 단위로 나눌지 정한다고 설명했는데요. 보통 분할된 청크 끝부분에서 맥락이 이어질 수 있도록 일부를 겹쳐서 분할합니다. 이를 청크 오버랩(chunk overlap)이라고 합니다.\\n청크의 벡터 값으로 유사도 계산을 하는 예시를 보여 드리겠습니다. 다음과 같이 세 개의 단락(청크)이 있고, '시장조사기관 IDC가 예측한 AI 소프트웨어 시장의 연평균 성장률은 어떻게 되나요?'라는 사용자 질문이 들어오면 각 단락과 질문이 임베딩되어 벡터 값이 매겨집니다. 그러면 벡터 값을 이루는 숫자 사이의 차이(거리)를 계산할 수 있어 질문의 벡터 값과 가장 거리가 가까운(즉, 가장 유사한) 단락이 프롬프트의 컨텍스트로 전달됩니다.\\n\\nLLM의 질문과 답변을 처리할 때와 마찬가지로 임베딩할 때도 비용이 발생합니다. 물론 답변에 소요되는 것보다는 부담이 덜하지만, 프로그램을 실행할 때마다 매번 임베딩을 한다면 계속 비용이 발생하는 셈입니다. 그래서 각 청크에 임베딩된 값을 벡터 스토어(vector store)에 저장해 두고, 데이터베이스에 검색어로 쿼리를 요청할 때마다 가져올 수 있게 합니다.\\n이처럼 문서를 로드해서 텍스트를 청크 단위로 분할하고 각각의 청크를 임베딩해서 유사도 계산을 위한 벡터 값을 저장하는 과정을 전처리 과정(pre-process)이라고 합니다.\\n\\nRAG 프로세스의 실행 단계 이해하기\\n이번에는 사전 단계 이후의 실행(runtime) 단계를 살펴보겠습니다.\\n- 5단계 | 리트리버: 질문이 주어지면, 이와 관련된 벡터를 벡터 데이터베이스에서 검색합니다. 질문에 가장 잘 맞는 책의 Chapter를 찾는 것과 유사합니다.\\n- 6단계 | 프롬프트: 검색된 정보를 바탕으로 언어 모델을 위한 질문을 구성합니다. 이는 정보를 바탕으로 어떻게 질문할지 결정하는 과정입니다.\\n- 7단계 | LLM: 구성된 프롬프트를 사용하여 언어 모델이 답변을 생성합니다. 즉, 수집된 정보를 바탕으로 과제나 보고서를 작성하는 학생과 같습니다.\\n- 8단계 | 체인 생성: 이전의 모든 과정을 하나의 파이프라인으로 묶어 주는 체인(chain)을 생성합니다.\"),\n",
       "  'language': 'Korean'},\n",
       " {'documents': Document(metadata={}, page_content='다섯 번째 리트리버(retriever) 단계는 벡터 데이터베이스에서 사용자 질문과 관련된 문서를 검색하는 핵심 과정입니다. 사용자가 질문을 입력하면 이를 임베딩 단계와 동일한 방식으로 벡터로 변환합니다. 이렇게 변환된 질문 벡터는 미리 준비된 데이터베이스의 문서 벡터들과 비교되어 유사성이 계산됩니다. 코사인 유사성(cosine similarity)이나 MMR(Max Marginal Relevance) 같은 알고리즘이 이 비교 과정에서 활용되며, 이를 통해 질문과 가장 관련이 깊은 단락들을 선별해 냅니다. 이때 k 값을 설정하여 선택할 청크의 수를 조절할 수 있습니다. 이렇게 찾아 낸 문서의 내용과 메타데이터는 다음 단계인 프롬프트 생성으로 넘어갑니다.\\n리트리버의 성능은 전체 시스템의 응답 품질과 직결됩니다. 관련성 높은 정보를 정확히 찾아내야 유용한 답변이 가능하기 때문입니다. 또한 효율적인 검색 알고리즘을 활용해 전체 응답 시간을 단축시켜 사용자 경험을 개선하는 것도 중요한데, 필요한 정보만 추출하는 과정은 시스템 자원의 사용을 최적화하고 불필요한 데이터 처리를 최소화할 수 있어 전체 시스템의 효율성을 높이는 데 중요한 역할을 합니다.\\n\\n여섯 번째 프롬프트 단계는 리트리버가 검색해 온 문서들을 바탕으로 언어 모델이 사용할 질문이나 명령을 만드는 과정입니다. 여러 문서에서 가져온 정보들은 다양한 관점이나 내용을 담고 있을 수 있는데, 이 단계에서 이런 정보들을 하나로 통합하고 언어 모델이 특정 컨텍스트 안에서 제대로 작동하도록 안내하는 역할을 합니다. 잘 구성된 프롬프트는 모델이 더 정확하고 관련성 높은 답변을 만들어 낼 수 있는 중요한 토대가 됩니다.\\n\\n일곱 번째 LLM(Large Language Model) 단계에서는 앞서 구성된 프롬프트를 입력으로 받아 대규모 언어 모델을 통해 실제 응답을 생성합니다. 이 과정에서 언어 모델의 능력을 최대한 활용하여 사용자 질문에 대한 정확하고 자연스러운 답변이 만들어집니다. 이 단계는 앞선 모든 과정의 결과물을 실제 사용자가 이해할 수 있는 형태로 변환하는 최종 관문이라 할 수 있습니다.\\n\\n마지막으로 체인 생성 단계는 LCEL(LangChain Expression Language) 문법을 활용해 앞서 설명한 일곱 단계를 하나로 묶어 완전한 RAG 파이프라인으로 조립하는 단계입니다. 체인의 구조를 좀 더 구체적으로 살펴보겠습니다. 사용자 질문은 두 갈래로 나뉘어 처리됩니다. 하나는 리트리버로 전달되어 필요한 정보를 검색하는 데 쓰이고, 하나는 RunnablePassthrough() 메서드를 통해 바로 프롬프트의 질문(question)으로 들어갑니다. 리트리버에 전달된 질문은 임베딩 표현으로 변환되어 벡터 스토어의 데이터베이스와 유사도 계산을 해서 가장 관련성이 높은 단락을 뽑아냅니다. 이렇게 선정한 k개의 단락은 프롬프트의 컨텍스트(context)로 전달되어 최종 응답 생성의 근거 자료로 활용됩니다.\\n\\n체인 생성과 질의를 코드로 간단히 나타내면 다음과 같습니다.\\nchain = (\\n    {\"context\": retriever, \"question\": RunnablePassthrough()}\\n    | prompt | llm | StrOutputParser()\\n)\\nquestion = \"삼성전자가 신규 개발한 AI의 이름은?\"\\nresponse = chain.invoke(question)\\nprint(response)\\n\\n직접 커스터마이즈한 RAG의 높은 성능\\n다음은 OpenAI 데브 데이(Dev Day) 프레젠테이션에서 공개된 내용의 일부입니다. AI로부터 좋은 답변을 얻기 위해서는 프롬프트 엔지니어링만으로는 성능을 올리는 데 한계가 있습니다. GPT는 전 세계 사람들이 사용하는 모델이기 때문에 평균적으로 답변을 잘하게끔 설계된 범용 모델입니다. 이러한 GPT 모델에 RAG를 활용해 컨텍스트를 더 최적화하면 문맥을 보완하여 더 구체적인 답변을 얻을 수 있으며, 여기에 파인 튜닝(미세 조정)을 더하면 원래 모델이 가진 잠재력을 최고 수준으로 끌어올려 상세한 답변을 얻음과 동시에 할루시네이션 현상도 줄일 수 있습니다.\\n\\n다음 그래프는 RAG에 다양한 기법을 적용하는 것에 따라 성능이 점진적으로 향상되는 수치를 보여 줍니다. 가장 기본적인 방법만 사용했을 때 45%였던 정확도는 추가적인 기법들의 적용에 따라 65%, 85%까지 향상되었고, 프롬프트 엔지니어링까지 더해져 최종적으로 98%의 정확도를 달성했습니다. 우리가 지금까지 사용해 온 ChatGPT의 실제 능력치가 45% 수준에 불과했다는 사실이 놀랍지 않나요?'),\n",
       "  'language': 'Korean'}]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a115dabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['- RAG(Retrieval-Augmented Generation)는 GPT 모델의 한계를 극복하기 위해 최신 정보와 신뢰할 수 있는 외부 데이터를 활용하여 응답 정확도를 향상시키는 기술이다.\\n- RAG는 ChatGPT의 최신 정보 부족, 내부 데이터 미반영, 보안 문제, 할루시네이션 현상 등의 문제를 해결할 수 있다.\\n- RAG를 통해 사용자는 개인 맞춤형 챗봇이나 특정 도메인에 최적화된 챗봇을 쉽게 생성할 수 있으며, 데이터베이스를 업데이트함으로써 최신 정보를 반영한 답변을 얻을 수 있다.\\n- RAG는 GPT가 사전 학습된 지식에 의존하지 않고 제공된 자료를 기반으로 정확한 답변을 생성할 수 있도록 돕는다.\\n- ChatGPT의 내장 RAG 시스템은 사용자가 문서를 업로드하고 질문할 때 그럴듯한 답변을 제공하지만, 이 정보의 정확성을 확인하기는 어렵다.', '- 한국개발연구원(KDI)의 2023년 하반기 경제전망 보고서는 국내외 경제 동향과 중단기 경제 전망을 분석하여 정부와 기업의 정책 수립에 도움을 주기 위해 작성되었다.\\n- 보고서는 고금리, 수출 회복, 내수 둔화 등 현재 경제 상황을 다루며, 2024년 경제 전망으로 완만한 회복세를 예측하고 다양한 경제 지표를 제시한다.\\n- 정책 방향으로는 재정정책, 통화정책, 금융정책을 제안하며, 대외 불확실성 요인에 대한 대응 방안을 모색한다.\\n- ChatGPT는 문서의 구체적인 데이터를 제공하지 못하는 경우가 있으며, 사용자가 문서 내용을 효과적으로 검색할 수 있도록 형식을 변경하는 것이 필요하다.\\n- RAG 기술은 최신 정보를 기반으로 답변을 제공하고, 답변 과정을 투명하게 모니터링할 수 있는 장점을 가지고 있다.', '- LangSmith 도구를 사용하여 LLM의 답변 추적 과정을 분석하고, 답변의 출처와 관련 문서를 확인할 수 있다.\\n- RAG 시스템은 LLM의 할루시네이션을 줄이는 데 효과적이며, 유효한 정보에 기반한 답변을 제공하도록 돕는다.\\n- LangChain은 대규모 언어 모델을 활용한 애플리케이션 개발을 위한 프레임워크로, 다양한 서비스에 쉽게 통합할 수 있다.\\n- RAG 시스템의 전체 프로세스를 LangChain을 통해 구현하여, 원하는 형태의 답변을 얻기 위해 세부 알고리즘을 조정할 수 있다.\\n- RAG 프로세스는 사용자의 질문에 대해 관련 정보를 데이터베이스에서 검색하여 LLM이 보다 정확한 답변을 생성하도록 지원한다.', '- 데이터 소스를 벡터 스토어로 활용하여 문서 로드, 텍스트 분할, 임베딩, 저장의 네 단계를 거쳐 전처리 과정을 진행한다.\\n- 문서 로드 단계에서는 외부 데이터 소스에서 필요한 문서를 불러오고, 텍스트 분할 단계에서는 문서를 청크 단위로 나눈다.\\n- 임베딩 단계에서는 청크를 벡터 형태로 변환하여 문서의 의미를 수치화하고, 벡터 스토어에 저장하여 나중에 빠르게 검색할 수 있도록 한다.\\n- 실행 단계에서는 질문에 대한 관련 벡터를 검색하고, 이를 바탕으로 언어 모델을 위한 질문을 구성하여 답변을 생성한다.\\n- 이 모든 과정은 RAG 프로세스의 일환으로, 효율적인 정보 검색과 처리를 위한 체인을 생성한다.', '- 리트리버 단계는 사용자 질문을 벡터로 변환하고, 데이터베이스에서 관련 문서를 검색하여 유사성을 계산하는 과정이다.\\n- 프롬프트 단계에서는 검색된 문서의 정보를 통합하여 언어 모델이 사용할 질문이나 명령을 생성한다.\\n- LLM 단계에서는 구성된 프롬프트를 통해 대규모 언어 모델이 사용자 질문에 대한 답변을 생성한다.\\n- 체인 생성 단계는 앞서 설명한 과정을 하나의 RAG 파이프라인으로 조립하는 과정이다.\\n- RAG를 활용한 프롬프트 최적화와 파인 튜닝을 통해 AI의 답변 정확도를 크게 향상시킬 수 있다.']\n"
     ]
    }
   ],
   "source": [
    "# 모든 문서에 대한 요약본을 출력합니다.\n",
    "print(map_chain.batch(input_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabca078",
   "metadata": {},
   "source": [
    "### Refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3f7cb684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are an expert summarizer.\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Your job is to produce a final summary\n",
      "\n",
      "We have provided an existing summary up to a certain point:\n",
      "\u001b[33;1m\u001b[1;3m{previous_summary}\u001b[0m\n",
      "\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "\u001b[33;1m\u001b[1;3m{current_summary}\u001b[0m\n",
      "------------\n",
      "Given the new context, refine the original summary in \u001b[33;1m\u001b[1;3m{language}\u001b[0m.\n",
      "If the context isn't useful, return the original summary.\n"
     ]
    }
   ],
   "source": [
    "# refine prompt 다운로드\n",
    "refine_prompt = hub.pull(\"teddynote/refine-prompt\")\n",
    "\n",
    "# 프롬프트 출력\n",
    "refine_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2a7e65d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refine llm 생성\n",
    "refine_llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model_name=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "# refine chain 생성\n",
    "refine_chain = refine_prompt | refine_llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "36b23a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain\n",
    "\n",
    "\n",
    "@chain\n",
    "def map_refine_chain(docs):\n",
    "\n",
    "    # map chain 생성\n",
    "    map_summary = hub.pull(\"teddynote/map-summary-prompt\")\n",
    "\n",
    "    map_chain = (\n",
    "        map_summary\n",
    "        | ChatOpenAI(\n",
    "            model_name=\"gpt-4o-mini\",\n",
    "            temperature=0,\n",
    "        )\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    input_doc = [{\"documents\": doc.page_content, \"language\": \"Korean\"} for doc in docs]\n",
    "\n",
    "    # 첫 번째 프롬프트, ChatOpenAI, 문자열 출력 파서를 연결하여 체인을 생성합니다.\n",
    "    doc_summaries = map_chain.batch(input_doc)\n",
    "\n",
    "    refine_prompt = hub.pull(\"teddynote/refine-prompt\")\n",
    "\n",
    "    refine_llm = ChatOpenAI(\n",
    "        model_name=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "        callbacks=[StreamingCallback()],\n",
    "        streaming=True,\n",
    "    )\n",
    "\n",
    "    refine_chain = refine_prompt | refine_llm | StrOutputParser()\n",
    "\n",
    "    previous_summary = doc_summaries[0]\n",
    "\n",
    "    for current_summary in doc_summaries[1:]:\n",
    "\n",
    "        previous_summary = refine_chain.invoke(\n",
    "            {\n",
    "                \"previous_summary\": previous_summary,\n",
    "                \"current_summary\": current_summary,\n",
    "                \"language\": \"Korean\",\n",
    "            }\n",
    "        )\n",
    "        print(\"\\n\\n-----------------\\n\\n\")\n",
    "\n",
    "    return previous_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7fc2f9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- RAG(Retrieval-Augmented Generation)는 GPT 모델의 한계를 극복하기 위해 최신 정보와 신뢰할 수 있는 외부 데이터를 활용하여 응답 정확도를 향상시키는 기술이다.\n",
      "- RAG는 사용자가 원하는 대로 데이터베이스와 모델을 커스터마이즈할 수 있어 특정 도메인에 특화된 챗봇 제작이 가능하다.\n",
      "- ChatGPT는 최신 정보 부족, 내부 데이터 미학습, 보안 문제, 할루시네이션 현상 등의 한계를 가지고 있으며, RAG는 이러한 문제를 해결할 수 있다.\n",
      "- RAG를 통해 최신 정보를 기반으로 답변하고, 내부 데이터베이스를 활용하여 개인 맞춤형 응답을 제공할 수 있다.\n",
      "- RAG 시스템을 고도화하면 답변의 정교함이 높아지고, 효율적인 정보 검색이 가능해진다.\n",
      "- 한국개발연구원(KDI)의 2023년 하반기 경제전망 보고서는 고금리, 수출 회복, 내수 둔화, 물가 상황 등을 분석하여 2024년 경제 전망을 제시하며, 재정정책, 통화정책, 금융정책 등의 방향을 제안한다. \n",
      "- RAG 시스템은 이러한 최신 경제 정보를 기반으로 질문에 대한 답변을 제공할 수 있으며, 구현 난이도가 낮아 개인이 쉽게 시도할 수 있는 수준이다.\n",
      "\n",
      "-----------------\n",
      "\n",
      "\n",
      "- RAG(Retrieval-Augmented Generation)는 GPT 모델의 한계를 극복하기 위해 최신 정보와 신뢰할 수 있는 외부 데이터를 활용하여 응답 정확도를 향상시키는 기술이다.\n",
      "- RAG는 사용자가 원하는 대로 데이터베이스와 모델을 커스터마이즈할 수 있어 특정 도메인에 특화된 챗봇 제작이 가능하다.\n",
      "- ChatGPT는 최신 정보 부족, 내부 데이터 미학습, 보안 문제, 할루시네이션 현상 등의 한계를 가지고 있으며, RAG는 이러한 문제를 해결할 수 있다.\n",
      "- RAG를 통해 최신 정보를 기반으로 답변하고, 내부 데이터베이스를 활용하여 개인 맞춤형 응답을 제공할 수 있다.\n",
      "- RAG 시스템을 고도화하면 답변의 정교함이 높아지고, 효율적인 정보 검색이 가능해진다.\n",
      "- LangChain은 대규모 언어 모델을 활용한 애플리케이션 개발을 위한 프레임워크로, RAG 시스템의 전체 프로세스를 구현하여 원하는 형태의 답변을 얻기 위해 세부 알고리즘을 조정할 수 있다.\n",
      "- LangSmith 도구를 사용하여 LLM의 답변 추적 과정을 분석하고, 이를 통해 답변의 원인을 파악하고 개선할 수 있다.\n",
      "- RAG 시스템은 LLM의 할루시네이션을 줄이는 데 효과적이며, 유효한 정보만을 기반으로 답변을 도출하도록 돕는다.\n",
      "- 한국개발연구원(KDI)의 2023년 하반기 경제전망 보고서는 고금리, 수출 회복, 내수 둔화, 물가 상황 등을 분석하여 2024년 경제 전망을 제시하며, 재정정책, 통화정책, 금융정책 등의 방향을 제안한다.\n",
      "- RAG 시스템은 이러한 최신 경제 정보를 기반으로 질문에 대한 답변을 제공할 수 있으며, 구현 난이도가 낮아 개인이 쉽게 시도할 수 있는 수준이다.\n",
      "\n",
      "-----------------\n",
      "\n",
      "\n",
      "- RAG(Retrieval-Augmented Generation)는 GPT 모델의 한계를 극복하기 위해 최신 정보와 신뢰할 수 있는 외부 데이터를 활용하여 응답 정확도를 향상시키는 기술이다.\n",
      "- RAG는 사용자가 원하는 대로 데이터베이스와 모델을 커스터마이즈할 수 있어 특정 도메인에 특화된 챗봇 제작이 가능하다.\n",
      "- ChatGPT는 최신 정보 부족, 내부 데이터 미학습, 보안 문제, 할루시네이션 현상 등의 한계를 가지고 있으며, RAG는 이러한 문제를 해결할 수 있다.\n",
      "- RAG를 통해 최신 정보를 기반으로 답변하고, 내부 데이터베이스를 활용하여 개인 맞춤형 응답을 제공할 수 있다.\n",
      "- RAG 시스템을 고도화하면 답변의 정교함이 높아지고, 효율적인 정보 검색이 가능해진다.\n",
      "- LangChain은 대규모 언어 모델을 활용한 애플리케이션 개발을 위한 프레임워크로, RAG 시스템의 전체 프로세스를 구현하여 원하는 형태의 답변을 얻기 위해 세부 알고리즘을 조정할 수 있다.\n",
      "- LangSmith 도구를 사용하여 LLM의 답변 추적 과정을 분석하고, 이를 통해 답변의 원인을 파악하고 개선할 수 있다.\n",
      "- RAG 시스템은 LLM의 할루시네이션을 줄이는 데 효과적이며, 유효한 정보만을 기반으로 답변을 도출하도록 돕는다.\n",
      "- 한국개발연구원(KDI)의 2023년 하반기 경제전망 보고서는 고금리, 수출 회복, 내수 둔화, 물가 상황 등을 분석하여 2024년 경제 전망을 제시하며, 재정정책, 통화정책, 금융정책 등의 방향을 제안한다.\n",
      "- RAG 시스템은 이러한 최신 경제 정보를 기반으로 질문에 대한 답변을 제공할 수 있으며, 구현 난이도가 낮아 개인이 쉽게 시도할 수 있는 수준이다.\n",
      "- RAG 시스템은 데이터 소스를 벡터 스토어로 활용하여 문서 로드, 텍스트 분할, 임베딩, 저장의 네 단계를 거쳐 정보를 처리한다. 문서 로드 단계에서는 외부 데이터 소스에서 필요한 문서를 불러오고, 텍스트 분할 단계에서는 문서를 청크로 나누어 처리한다. 임베딩 단계에서는 청크를 벡터 형태로 변환하여 문서의 의미를 수치화하고, 벡터 스토어에 저장하여 나중에 빠르게 검색할 수 있도록 한다. 실행 단계에서는 질문에 대한 관련 벡터를 검색하고, 이를 바탕으로 언어 모델에 질문을 구성하여 답변을 생성한다. 이 모든 과정은 전처리 과정과 실행 단계로 나뉘며, 최종적으로 체인을 생성하여 효율적인 정보 처리를 가능하게 한다.\n",
      "\n",
      "-----------------\n",
      "\n",
      "\n",
      "- RAG(Retrieval-Augmented Generation)는 GPT 모델의 한계를 극복하기 위해 최신 정보와 신뢰할 수 있는 외부 데이터를 활용하여 응답 정확도를 향상시키는 기술이다.\n",
      "- RAG는 사용자가 원하는 대로 데이터베이스와 모델을 커스터마이즈할 수 있어 특정 도메인에 특화된 챗봇 제작이 가능하다.\n",
      "- ChatGPT는 최신 정보 부족, 내부 데이터 미학습, 보안 문제, 할루시네이션 현상 등의 한계를 가지고 있으며, RAG는 이러한 문제를 해결할 수 있다.\n",
      "- RAG를 통해 최신 정보를 기반으로 답변하고, 내부 데이터베이스를 활용하여 개인 맞춤형 응답을 제공할 수 있다.\n",
      "- RAG 시스템을 고도화하면 답변의 정교함이 높아지고, 효율적인 정보 검색이 가능해진다.\n",
      "- LangChain은 대규모 언어 모델을 활용한 애플리케이션 개발을 위한 프레임워크로, RAG 시스템의 전체 프로세스를 구현하여 원하는 형태의 답변을 얻기 위해 세부 알고리즘을 조정할 수 있다.\n",
      "- LangSmith 도구를 사용하여 LLM의 답변 추적 과정을 분석하고, 이를 통해 답변의 원인을 파악하고 개선할 수 있다.\n",
      "- RAG 시스템은 LLM의 할루시네이션을 줄이는 데 효과적이며, 유효한 정보만을 기반으로 답변을 도출하도록 돕는다.\n",
      "- 한국개발연구원(KDI)의 2023년 하반기 경제전망 보고서는 고금리, 수출 회복, 내수 둔화, 물가 상황 등을 분석하여 2024년 경제 전망을 제시하며, 재정정책, 통화정책, 금융정책 등의 방향을 제안한다.\n",
      "- RAG 시스템은 이러한 최신 경제 정보를 기반으로 질문에 대한 답변을 제공할 수 있으며, 구현 난이도가 낮아 개인이 쉽게 시도할 수 있는 수준이다.\n",
      "- RAG 시스템은 데이터 소스를 벡터 스토어로 활용하여 문서 로드, 텍스트 분할, 임베딩, 저장의 네 단계를 거쳐 정보를 처리한다. 문서 로드 단계에서는 외부 데이터 소스에서 필요한 문서를 불러오고, 텍스트 분할 단계에서는 문서를 청크로 나누어 처리한다. 임베딩 단계에서는 청크를 벡터 형태로 변환하여 문서의 의미를 수치화하고, 벡터 스토어에 저장하여 나중에 빠르게 검색할 수 있도록 한다. \n",
      "- 다섯 번째 리트리버 단계는 사용자 질문을 벡터로 변환하고, 데이터베이스에서 관련 문서를 검색하여 유사성을 계산하는 과정이다. 여섯 번째 프롬프트 단계에서는 검색된 문서 정보를 통합하여 언어 모델이 사용할 질문이나 명령을 생성한다. 일곱 번째 LLM 단계에서는 구성된 프롬프트를 통해 대규모 언어 모델이 사용자 질문에 대한 응답을 생성한다. 체인 생성 단계는 앞서 설명한 일곱 단계를 하나로 묶어 RAG 파이프라인을 완성하는 과정이다.\n",
      "- RAG를 활용하여 GPT 모델의 성능을 최적화하고, 프롬프트 엔지니어링과 파인 튜닝을 통해 정확도를 98%까지 향상시킬 수 있다.\n",
      "\n",
      "-----------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "refined_summary = map_refine_chain.invoke(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19f782c",
   "metadata": {},
   "source": [
    "## Chain of Density\n",
    "\n",
    "초기 요약 생성 -> 길이는 그대로 두면서 누락된 중요 개체들을 반복적으로 통합 -> 반복 -> 짧은 요약이지만 핵심 정보를 포함한 요약으로 수렴됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "10a44ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "As an expert copy-writer, you will write increasingly concise, entity-dense summaries of the user provided \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m. The initial summary should be under \u001b[33;1m\u001b[1;3m{max_words}\u001b[0m words and contain \u001b[33;1m\u001b[1;3m{entity_range}\u001b[0m informative Descriptive Entities from the \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m.\n",
      "\n",
      "A Descriptive Entity is:\n",
      "- Relevant: to the main story.\n",
      "- Specific: descriptive yet concise (5 words or fewer).\n",
      "- Faithful: present in the \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m.\n",
      "- Anywhere: located anywhere in the \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m.\n",
      "\n",
      "# Your Summarization Process\n",
      "- Read through the \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m and the all the below sections to get an understanding of the task.\n",
      "- Pick \u001b[33;1m\u001b[1;3m{entity_range}\u001b[0m informative Descriptive Entities from the \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m (\";\" delimited, do not add spaces).\n",
      "- In your output JSON list of dictionaries, write an initial summary of max \u001b[33;1m\u001b[1;3m{max_words}\u001b[0m words containing the Entities.\n",
      "- You now have `[{\"missing_entities\": \"...\", \"denser_summary\": \"...\"}]`\n",
      "\n",
      "Then, repeat the below 2 steps \u001b[33;1m\u001b[1;3m{iterations}\u001b[0m times:\n",
      "\n",
      "- Step 1. In a new dict in the same list, identify \u001b[33;1m\u001b[1;3m{entity_range}\u001b[0m new informative Descriptive Entities from the \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m which are missing from the previously generated summary.\n",
      "- Step 2. Write a new, denser summary of identical length which covers every Entity and detail from the previous summary plus the new Missing Entities.\n",
      "\n",
      "A Missing Entity is:\n",
      "- An informative Descriptive Entity from the \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m as defined above.\n",
      "- Novel: not in the previous summary.\n",
      "\n",
      "# Guidelines\n",
      "- The first summary should be long (max \u001b[33;1m\u001b[1;3m{max_words}\u001b[0m words) yet highly non-specific, containing little information beyond the Entities marked as missing. Use overly verbose language and fillers (e.g., \"this \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m discusses\") to reach ~\u001b[33;1m\u001b[1;3m{max_words}\u001b[0m words.\n",
      "- Make every word count: re-write the previous summary to improve flow and make space for additional entities.\n",
      "- Make space with fusion, compression, and removal of uninformative phrases like \"the \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m discusses\".\n",
      "- The summaries should become highly dense and concise yet self-contained, e.g., easily understood without the \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m.\n",
      "- Missing entities can appear anywhere in the new summary.\n",
      "- Never drop entities from the previous summary. If space cannot be made, add fewer new entities.\n",
      "- You're finished when your JSON list has 1+\u001b[33;1m\u001b[1;3m{iterations}\u001b[0m dictionaries of increasing density.\n",
      "\n",
      "# IMPORTANT\n",
      "- Remember, to keep each summary to max \u001b[33;1m\u001b[1;3m{max_words}\u001b[0m words.\n",
      "- Never remove Entities or details. Only add more from the \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m.\n",
      "- Do not discuss the \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m itself, focus on the content: informative Descriptive Entities, and details.\n",
      "- Remember, if you're overusing filler phrases in later summaries, or discussing the \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m itself, not its contents, choose more informative Descriptive Entities and include more details from the \u001b[33;1m\u001b[1;3m{content_category}\u001b[0m.\n",
      "- Answer with a minified JSON list of dictionaries with keys \"missing_entities\" and \"denser_summary\".\n",
      "- \"denser_summary\" should be written in the same language as the \"content\".\n",
      "\n",
      "## Example output\n",
      "[{\"missing_entities\": \"ent1;ent2\", \"denser_summary\": \"<vague initial summary with entities 'ent1','ent2'>\"}, {\"missing_entities\": \"ent3\", \"denser_summary\": \"denser summary with 'ent1','ent2','ent3'\"}, ...]\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\u001b[33;1m\u001b[1;3m{content_category}\u001b[0m:\n",
      "\u001b[33;1m\u001b[1;3m{content}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Chain of Density 프롬프트 다운로드\n",
    "cod_prompt = hub.pull(\"teddynote/chain-of-density-prompt\")\n",
    "\n",
    "cod_prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6699df31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import SimpleJsonOutputParser\n",
    "\n",
    "# {content}를 제외한 모든 입력에 대한 기본값 지정\n",
    "cod_chain_inputs = {\n",
    "    \"content\": lambda d: d.get(\"content\"),\n",
    "    \"content_category\": lambda d: d.get(\"content_category\", \"Research/Technical Book\"),\n",
    "    \"entity_range\": lambda d: d.get(\"entity_range\", \"3-5\"),\n",
    "    \"max_words\": lambda d: int(d.get(\"max_words\", 120)),\n",
    "    \"iterations\": lambda d: int(d.get(\"iterations\", 5)),\n",
    "}\n",
    "\n",
    "# Chain of Density 프롬프트 다운로드\n",
    "cod_prompt = hub.pull(\"teddynote/chain-of-density-prompt\")\n",
    "\n",
    "# Chain of Density 체인 생성\n",
    "cod_chain = (\n",
    "    cod_chain_inputs\n",
    "    | cod_prompt\n",
    "    | ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "    | SimpleJsonOutputParser()\n",
    ")\n",
    "\n",
    "# 두 번째 체인 생성, 최종 요약만 추출 (스트리밍 불가능, 최종 결과가 필요함)\n",
    "cod_final_summary_chain = cod_chain | (\n",
    "    lambda output: output[-1].get(\n",
    "        \"denser_summary\", '오류: 마지막 딕셔너리에 \"denser_summary\" 키가 없습니다'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9a1aada9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'missing_entities': '리트리버 단계;프롬프트 단계;LLM 단계;체인 생성 단계;RAG 파이프라인', 'denser_summary': '이 연구에서는 리트리버 단계, 프롬프트 단계, LLM 단계, 체인 생성 단계, RAG 파이프라인을 통해 사용자 질문을 처리하는 방법을 설명한다. 리트리버 단계는 질문을 벡터로 변환하여 관련 문서를 검색하는 과정이다. 프롬프트 단계에서는 검색된 문서를 바탕으로 언어 모델이 사용할 질문이나 명령을 생성한다. LLM 단계는 구성된 프롬프트를 입력으로 받아 대규모 언어 모델을 통해 응답을 생성한다. 마지막으로, 체인 생성 단계는 이 모든 단계를 통합하여 완전한 RAG 파이프라인을 조립한다.'}, {'missing_entities': '프롬프트 최적화;파인 튜닝', 'denser_summary': '이 연구에서는 리트리버 단계, 프롬프트 단계, LLM 단계, 체인 생성 단계, RAG 파이프라인을 통해 사용자 질문을 처리하는 방법을 설명한다. 리트리버 단계는 질문을 벡터로 변환하여 관련 문서를 검색하는 과정이다. 프롬프트 단계에서는 검색된 문서를 바탕으로 언어 모델이 사용할 질문이나 명령을 생성한다. LLM 단계는 구성된 프롬프트를 입력으로 받아 대규모 언어 모델을 통해 응답을 생성한다. 마지막으로, 체인 생성 단계는 이 모든 단계를 통합하여 완전한 RAG 파이프라인을 조립하며, 프롬프트 최적화와 파인 튜닝을 통해 모델 성능을 극대화할 수 있다.'}, {'missing_entities': '사용자 질문;대규모 언어 모델', 'denser_summary': '이 연구에서는 리트리버 단계, 프롬프트 단계, LLM 단계, 체인 생성 단계, RAG 파이프라인을 통해 사용자 질문을 처리하는 방법을 설명한다. 리트리버 단계는 사용자 질문을 벡터로 변환하여 관련 문서를 검색하는 과정이다. 프롬프트 단계에서는 검색된 문서를 바탕으로 언어 모델이 사용할 질문이나 명령을 생성한다. LLM 단계는 구성된 프롬프트를 입력으로 받아 대규모 언어 모델을 통해 사용자 질문에 대한 응답을 생성한다. 마지막으로, 체인 생성 단계는 이 모든 단계를 통합하여 완전한 RAG 파이프라인을 조립하며, 프롬프트 최적화와 파인 튜닝을 통해 모델 성능을 극대화할 수 있다.'}, {'missing_entities': '모델 성능', 'denser_summary': '이 연구에서는 리트리버 단계, 프롬프트 단계, LLM 단계, 체인 생성 단계, RAG 파이프라인을 통해 사용자 질문을 처리하는 방법을 설명한다. 리트리버 단계는 사용자 질문을 벡터로 변환하여 관련 문서를 검색하는 과정이다. 프롬프트 단계에서는 검색된 문서를 바탕으로 언어 모델이 사용할 질문이나 명령을 생성한다. LLM 단계는 구성된 프롬프트를 입력으로 받아 대규모 언어 모델을 통해 사용자 질문에 대한 응답을 생성한다. 마지막으로, 체인 생성 단계는 이 모든 단계를 통합하여 완전한 RAG 파이프라인을 조립하며, 프롬프트 최적화와 파인 튜닝을 통해 모델 성능을 극대화할 수 있다.'}, {'missing_entities': '', 'denser_summary': '이 연구에서는 리트리버 단계, 프롬프트 단계, LLM 단계, 체인 생성 단계, RAG 파이프라인을 통해 사용자 질문을 처리하는 방법을 설명한다. 리트리버 단계는 사용자 질문을 벡터로 변환하여 관련 문서를 검색하는 과정이다. 프롬프트 단계에서는 검색된 문서를 바탕으로 언어 모델이 사용할 질문이나 명령을 생성한다. LLM 단계는 구성된 프롬프트를 입력으로 받아 대규모 언어 모델을 통해 사용자 질문에 대한 응답을 생성한다. 마지막으로, 체인 생성 단계는 이 모든 단계를 통합하여 완전한 RAG 파이프라인을 조립하며, 프롬프트 최적화와 파인 튜닝을 통해 모델 성능을 극대화한다.'}]\n",
      "\n",
      "### CoD Summary 1/5, 추가된 엔티티(entity): 리트리버 단계, 프롬프트 단계, LLM 단계, 체인 생성 단계, RAG 파이프라인\n",
      "\n",
      "이 연구에서는 리트리버 단계, 프롬프트 단계, LLM 단계, 체인 생성 단계, RAG 파이프라인을 통해 사용자 질문을 처리하는 방법을 설명한다.\n",
      "리트리버 단계는 질문을 벡터로 변환하여 관련 문서를 검색하는 과정이다. 프롬프트 단계에서는 검색된 문서를 바탕으로 언어 모델이 사용할 질문이나\n",
      "명령을 생성한다. LLM 단계는 구성된 프롬프트를 입력으로 받아 대규모 언어 모델을 통해 응답을 생성한다. 마지막으로, 체인 생성 단계는 이\n",
      "모든 단계를 통합하여 완전한 RAG 파이프라인을 조립한다.\n",
      "\n",
      "### CoD Summary 2/5, 추가된 엔티티(entity): 프롬프트 최적화, 파인 튜닝\n",
      "\n",
      "이 연구에서는 리트리버 단계, 프롬프트 단계, LLM 단계, 체인 생성 단계, RAG 파이프라인을 통해 사용자 질문을 처리하는 방법을 설명한다.\n",
      "리트리버 단계는 질문을 벡터로 변환하여 관련 문서를 검색하는 과정이다. 프롬프트 단계에서는 검색된 문서를 바탕으로 언어 모델이 사용할 질문이나\n",
      "명령을 생성한다. LLM 단계는 구성된 프롬프트를 입력으로 받아 대규모 언어 모델을 통해 응답을 생성한다. 마지막으로, 체인 생성 단계는 이\n",
      "모든 단계를 통합하여 완전한 RAG 파이프라인을 조립하며, 프롬프트 최적화와 파인 튜닝을 통해 모델 성능을 극대화할 수 있다.\n",
      "\n",
      "### CoD Summary 3/5, 추가된 엔티티(entity): 사용자 질문, 대규모 언어 모델\n",
      "\n",
      "이 연구에서는 리트리버 단계, 프롬프트 단계, LLM 단계, 체인 생성 단계, RAG 파이프라인을 통해 사용자 질문을 처리하는 방법을 설명한다.\n",
      "리트리버 단계는 사용자 질문을 벡터로 변환하여 관련 문서를 검색하는 과정이다. 프롬프트 단계에서는 검색된 문서를 바탕으로 언어 모델이 사용할\n",
      "질문이나 명령을 생성한다. LLM 단계는 구성된 프롬프트를 입력으로 받아 대규모 언어 모델을 통해 사용자 질문에 대한 응답을 생성한다.\n",
      "마지막으로, 체인 생성 단계는 이 모든 단계를 통합하여 완전한 RAG 파이프라인을 조립하며, 프롬프트 최적화와 파인 튜닝을 통해 모델 성능을\n",
      "극대화할 수 있다.\n",
      "\n",
      "### CoD Summary 4/5, 추가된 엔티티(entity): 모델 성능\n",
      "\n",
      "이 연구에서는 리트리버 단계, 프롬프트 단계, LLM 단계, 체인 생성 단계, RAG 파이프라인을 통해 사용자 질문을 처리하는 방법을 설명한다.\n",
      "리트리버 단계는 사용자 질문을 벡터로 변환하여 관련 문서를 검색하는 과정이다. 프롬프트 단계에서는 검색된 문서를 바탕으로 언어 모델이 사용할\n",
      "질문이나 명령을 생성한다. LLM 단계는 구성된 프롬프트를 입력으로 받아 대규모 언어 모델을 통해 사용자 질문에 대한 응답을 생성한다.\n",
      "마지막으로, 체인 생성 단계는 이 모든 단계를 통합하여 완전한 RAG 파이프라인을 조립하며, 프롬프트 최적화와 파인 튜닝을 통해 모델 성능을\n",
      "극대화할 수 있다.\n",
      "\n",
      "### CoD Summary 5/5, 추가된 엔티티(entity): \n",
      "\n",
      "이 연구에서는 리트리버 단계, 프롬프트 단계, LLM 단계, 체인 생성 단계, RAG 파이프라인을 통해 사용자 질문을 처리하는 방법을 설명한다.\n",
      "리트리버 단계는 사용자 질문을 벡터로 변환하여 관련 문서를 검색하는 과정이다. 프롬프트 단계에서는 검색된 문서를 바탕으로 언어 모델이 사용할\n",
      "질문이나 명령을 생성한다. LLM 단계는 구성된 프롬프트를 입력으로 받아 대규모 언어 모델을 통해 사용자 질문에 대한 응답을 생성한다.\n",
      "마지막으로, 체인 생성 단계는 이 모든 단계를 통합하여 완전한 RAG 파이프라인을 조립하며, 프롬프트 최적화와 파인 튜닝을 통해 모델 성능을\n",
      "극대화한다.\n",
      "\n",
      "\n",
      "============== [최종 요약] =================\n",
      "\n",
      "이 연구에서는 리트리버 단계, 프롬프트 단계, LLM 단계, 체인 생성 단계, RAG 파이프라인을 통해 사용자 질문을 처리하는 방법을 설명한다. 리트리버 단계는 사용자 질문을 벡터로 변환하여 관련 문서를 검색하는 과정이다. 프롬프트 단계에서는 검색된 문서를 바탕으로 언어 모델이 사용할 질문이나 명령을 생성한다. LLM 단계는 구성된 프롬프트를 입력으로 받아 대규모 언어 모델을 통해 사용자 질문에 대한 응답을 생성한다. 마지막으로, 체인 생성 단계는 이 모든 단계를 통합하여 완전한 RAG 파이프라인을 조립하며, 프롬프트 최적화와 파인 튜닝을 통해 모델 성능을 극대화한다.\n"
     ]
    }
   ],
   "source": [
    "# 결과를 저장할 빈 리스트 초기화\n",
    "results: list[dict[str, str]] = []\n",
    "\n",
    "# cod_chain을 스트리밍 모드로 실행하고 부분적인 JSON 결과를 처리\n",
    "for partial_json in cod_chain.stream(\n",
    "    {\"content\": doc, \"content_category\": \"Research/Technical Book\"}\n",
    "):\n",
    "    # 각 반복마다 results를 업데이트\n",
    "    results = partial_json\n",
    "\n",
    "    # 현재 결과를 같은 줄에 출력 (캐리지 리턴을 사용하여 이전 출력을 덮어씀)\n",
    "    print(results, end=\"\\r\", flush=True)\n",
    "\n",
    "# 총 요약 수 계산\n",
    "total_summaries = len(results)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 각 요약을 순회하며 처리\n",
    "i = 1\n",
    "for cod in results:\n",
    "    # 누락된 엔티티들을 추출하고 포맷팅\n",
    "    added_entities = \", \".join(\n",
    "        [\n",
    "            ent.strip()\n",
    "            for ent in cod.get(\n",
    "                \"missing_entities\", 'ERR: \"missing_entiies\" key not found'\n",
    "            ).split(\";\")\n",
    "        ]\n",
    "    )\n",
    "    # 더 밀도 있는 요약 추출\n",
    "    summary = cod.get(\"denser_summary\", 'ERR: missing key \"denser_summary\"')\n",
    "\n",
    "    # 요약 정보 출력 (번호, 총 개수, 추가된 엔티티)\n",
    "    print(\n",
    "        f\"### CoD Summary {i}/{total_summaries}, 추가된 엔티티(entity): {added_entities}\"\n",
    "        + \"\\n\"\n",
    "    )\n",
    "    # 요약 내용을 80자 너비로 줄바꿈하여 출력\n",
    "    print(textwrap.fill(summary, width=80) + \"\\n\")\n",
    "    i += 1\n",
    "\n",
    "print(\"\\n============== [최종 요약] =================\\n\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2bd72271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 연구에서는 리트리버 단계, 프롬프트 단계, LLM 단계, 체인 생성 단계, RAG 파이프라인을 통해 사용자 질문을 처리하는 방법을 설명한다. 리트리버 단계는 사용자 질문을 벡터로 변환하여 관련 문서를 검색하는 과정이다. 프롬프트 단계에서는 검색된 문서를 바탕으로 언어 모델이 사용할 질문이나 명령을 생성한다. LLM 단계는 구성된 프롬프트를 입력으로 받아 대규모 언어 모델을 통해 사용자 질문에 대한 응답을 생성한다. 마지막으로, 체인 생성 단계는 이 모든 단계를 통합하여 완전한 RAG 파이프라인을 조립하며, 프롬프트 최적화와 파인 튜닝을 통해 모델 성능을 극대화한다.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac6d498",
   "metadata": {},
   "source": [
    "## Clustering-Map-Refine\n",
    "\n",
    "기존 Map-Refine기법도 좋은 방법이지만 더 나아가 비슷한 청크끼리 묶어서 각 클러스터 중심에 가까운 텍스트만 요약하고 Refine 방식으로 보강하는 방식\n",
    "\n",
    "즉 비슷한 내용은 모아서 요약하고 그 요약을 점진적으로 보강하는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "db498e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13112"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 하나의 Text 로 모든 문서를 연결합니다.\n",
    "texts = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "96f1a011",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "split_docs = text_splitter.split_text(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "44e51772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fe71ad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "vectors = embeddings.embed_documents(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "059a472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 클러스터 수를 선택하면 문서의 콘텐츠에 따라 조정할 수 있습니다.\n",
    "num_clusters = 10\n",
    "\n",
    "# Perform K-means clustering\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=123).fit(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fc886c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, 9, 9, 9, 1, 5, 5, 1, 1, 4, 4, 9, 7, 2, 4, 2, 2, 9, 9, 6,\n",
       "       6, 8, 0, 0, 0, 6, 3, 7, 7, 3, 3, 7, 4, 4])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 확인\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "adf54a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# 경고 제거\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# t-SNE 수행 및 2차원으로 축소\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "reduced_data_tsne = tsne.fit_transform(np.array(vectors))\n",
    "\n",
    "# seaborn 스타일 설정\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# 축소된 데이터 플롯\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(\n",
    "    x=reduced_data_tsne[:, 0],\n",
    "    y=reduced_data_tsne[:, 1],\n",
    "    hue=kmeans.labels_,\n",
    "    palette=\"deep\",\n",
    "    s=100,\n",
    ")\n",
    "plt.xlabel(\"Dimension 1\", fontsize=12)\n",
    "plt.ylabel(\"Dimension 2\", fontsize=12)\n",
    "plt.title(\"Clustered Embeddings\", fontsize=16)\n",
    "plt.legend(title=\"Cluster\", title_fontsize=12)\n",
    "\n",
    "# 배경색 설정\n",
    "plt.gcf().patch.set_facecolor(\"white\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2e38fb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 가장 가까운 점들을 저장할 빈 리스트 생성\n",
    "closest_indices = []\n",
    "\n",
    "# 클러스터 수만큼 반복\n",
    "for i in range(num_clusters):\n",
    "\n",
    "    # 해당 클러스터 중심으로부터의 거리 목록 구하기\n",
    "    distances = np.linalg.norm(vectors - kmeans.cluster_centers_[i], axis=1)\n",
    "\n",
    "    # 가장 가까운 점의 인덱스 찾기 (argmin을 사용하여 최소 거리 찾기)\n",
    "    closest_index = np.argmin(distances)\n",
    "\n",
    "    # 해당 인덱스를 가장 가까운 인덱스 리스트에 추가\n",
    "    closest_indices.append(closest_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7e8284f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24, 9, 18, 28, 2, 8, 22, 14, 23, 19]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "43f5a999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 8, 9, 14, 18, 19, 22, 23, 24, 28]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문서의 요약을 순서대로 진행하기 위하여 오름차순 정렬\n",
    "selected_indices = sorted(closest_indices)\n",
    "selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1f0c0bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='ChatGPT의 한계를 보완하기 위해 주목받은 RAG\\nRAG는 ChatGPT의 한계를 보완하기 위해 주목받기 시작한 기술입니다. RAG란 Retrieval-Augmented Generation의 줄임말로, 검색(Retrieval), 증강(Augmented), 생성(Generation)이라는 의미를 담고 있으며, 거대 언어 모델(LLM; Large Language Model)이 외부의 신뢰할 수 있는 지식 데이터베이스를 참조하여 최적화된 응답을 생성하는 기술입니다.\\n\\nRAG의 다양한 방법론을 활용하여 지속적으로 업그레이드하면 ChatGPT만 사용했을 때 50점 수준이었던 답변의 품질을 80점, 90점대로 끌어올릴 수 있습니다. 적절한 RAG를 적용하면 앞서 언급된 문제점들을 다음과 같이 개선할 수 있습니다.'),\n",
       " Document(metadata={}, page_content='4. 위험 요인으로는 국제유가 변동, 중국의 경제 상황 변화 등 대외 불확실성이 높은 점을 지적하며, 이에 대한 대응 방안을 모색합니다.\\n이 보고서는 정부 및 기업의 정책 결정에 중요한 정보를 제공하며, 경제 상황에 대한 깊은 이해와 미래 전망에 대한 지침을 담고 있습니다.'),\n",
       " Document(metadata={}, page_content='문서 내용에 대해 더 자세히 알아보고자 세부 내용을 선택하여 다시 질문하고, 반드시 문서의 내용을 바탕으로 답변해 달라고 요청했습니다. 그러나 ChatGPT는 해당 내용에 대한 구체적인 데이터를 제공하지 않는다는 이상한 답변을 내놓았습니다. 문서에 분명히 해당 내용이 있음에 도 ChatGPT가 관련 정보를 찾지 못하는 현상이 발생했습니다.\\n보고서에서는 유로존의 전체 및 청년 실업률에 대한 구체적인 데이터를 제공하지 않습니다. 이 문서는 한국의 경제 상황과 전망에 초점을 맞추고 있어, 유로존의 실업률과 같은 특정 국제 경제 지표에 대한 세부 수치는 포함되어 있지 않습니다. 유로존의 실업률 정보가 필요하시다면, 유럽연합 통계국(Eurostat)의 공식 웹사이트에서 최신 데이터를 찾으실 수 있을 것입니다.'),\n",
       " Document(metadata={}, page_content=\"실제 예시를 통해 답변 추적 과정을 확인해 보겠습니다. LLM의 동작 과정을 추적하는 도구인 LangSmith에서 '삼성전자에서 자체 개발한 AI의 이름은?'이라고 질문을 던지면 왼쪽 추적 과정에서 답변 도출까지의 세부 과정, 소요 시간, 토큰 수 등을 확인할 수 있습니다. 이는 간단한 예시이지만, 추후 더 복잡한 설계를 진행한다고 해도 이러한 과정을 더욱 심도 있게 분석할 수 있습니다.\\n실제로 Retriever를 클릭하면 질문(query)이 입력되었을 때 어떤 문서(DOCUMENTS)의 어느 구절에서 관련 내용을 검색했는지를 다음과 같이 상세하게 확인할 수 있습니다.\\n또한 해당 문서들을 각각 클릭해서 열어 보면 실제 텍스트 내용까지도 확인할 수 있습니다. 이렇게 세부 과정을 확인하면 답변이 잘 나오지 않았을 경우 그 원인을 추적하여 결과를 개선할 수 있습니다.\"),\n",
       " Document(metadata={}, page_content=\"LangChain으로 구현할 RAG 시스템 전체 프로세스\\nChatGPT는 자체 RAG 시스템을 통해 답변을 제공하지만, 더 나은 답변을 위해 세부 알고리즘을 조정할 수 없다는 문제가 있습니다. 이제 우리는 LangChain을 통해 RAG의 모든 세부 프로세스를 한 땀 한 땀 구현할 것입니다. 한마디로 '튜닝'을 하는 것이죠. 우리가 원하는 형태의 답변을 얻을 때까지 각 과정을 투명하게 개선하고, 그 방법론을 체계적으로 정립해 놓으면 다양한 비즈니스 환경에서도 얼마든지 활용 가능한 수준의 성능에 도달할 수 있습니다.\\n다음은 RAG 시스템의 전체 프로세스입니다. 이 그림이 처음에는 복잡해 보일 수 있지만, 각 세부 과정을 하나씩 익혀 나가면 어렵지 않게 이해할 수 있습니다.\"),\n",
       " Document(metadata={}, page_content='RAG 프로세스의 사전 단계 이해하기\\nRAG를 쓰는 목적을 이해하기 위해 GPT로 질문을 해서 답변을 받는 과정을 살펴봅시다. 먼저 사용자가 GPT에 “삼성전자가 신규 개발한 AI가 뭐야?\" 같은 질문을 입력합니다. 사용자의 질문이 프롬프트에 들어오면 LLM에 전달되어 답변을 출력합니다. 이때 GPT는 아무런 참고할 만한 정보를 따로 받지 않았기 때문에 사전 학습된 내용만으로 답변을 줄 수밖에 없습니다. 만약 GPT가 현재 상황과 다른 오래된 정보만 알고 있다면 답변에서 할루시네이션이 일어나기 십상입니다.\\n\\n반면 RAG에서는 미리 참고할 정보(가령 PDF, CSV 등)를 데이터베이스나 문서 형태로 저장해 둡니다. 사용자가 질문을 입력하면 리트리버(retriever)가 해당 질문과 유사성이 높은 문서를 데이터베이스에서 찾아 반환하고, 이를 프롬프트에 포함하여 LLM이 컨텍스트(context)에서 필요한 내용을 검색해서 답변을 생성하도록 돕습니다.'),\n",
       " Document(metadata={}, page_content='- 3단계 | 임베딩(Embedding): 분할된 청크를 벡터 형태로 변환하여 문서의 의미를 수치화합니다. 자연어를 컴퓨터가 이해할 수 있는 수치로 변경하는 과정입니다.\\n- 4단계 | 벡터 스토어 저장: 임베딩된 청크를 데이터베이스에 저장합니다. 임베딩된 벡터들을 데이터베이스에 저장합니다. 이는 요약된 키워드를 색인으로 뽑아서 나중에 빠르게 찾을 수 있게 정리해 두는 과정입니다.'),\n",
       " Document(metadata={}, page_content=\"먼저 문서 로드 단계에서는 PDF, 엑셀, 논문, 이미지, 데이터베이스 등 문서를 로드합니다. 가령 PDF 파일을 로드하면 그 안에 있는 텍스트를 긁어 오는 작업을 합니다.\\n그다음은 텍스트 분할입니다. '삼성전자가 신규 개발한 AI가 뭐야?'라는 질문에 답하려면 '인공지능 산업의 최신 동향' 보고서 PDF에서 18페이지의 일부 내용만 가져와서 답변하면 됩니다. 이처럼 전체 정보를 다 프롬프트에 쓰지 않고, 청크라는 단위로 내용을 분할합니다. 토큰 수를 기준으로 청크 크기를 지정하면, 해당 분량의 청크로 분할됩니다. 가령 청크 크기를 1,000토큰으로 잡고, 한 페이지에 청크가 세 개 정도 들어간다고 가정해 보겠습니다. 그러면 23페이지의 보고서 내용이 69개의 청크로 분할되어 저장됩니다.\"),\n",
       " Document(metadata={}, page_content=\"사용자 질문이 들어오면 질문의 내용과 각각의 청크에 대해 유사도 계산을 해서 가장 관련성이 높은 청크를 뽑아내는 작업을 합니다. 유사도를 계산하기 위해 각 청크의 값을 수학적인 표현으로 바꿔야 하는데 이것을 임베딩이라고 합니다. 자연어는 복잡하고 다양한 의미를 내포하고 있는데, 임베딩을 통해 텍스트를 정량화된 숫자 값으로 변환하면 컴퓨터가 문서의 내용과 의미를 더 잘 이해해서 처리할 수 있습니다.\\n쉬운 예를 들어 임베딩을 설명해 보겠습니다. '매운맛', '신맛', '단맛'이라는 정보를 임베딩해서 각각 0.1, 0.7, 0.9와 같은 값을 매깁니다. 그러면 사용자가 '새콤달달한 맛'이라는 정보를 입력하면, '신맛'과 '단맛' 사이의 중간 지점인 0.8이라는 값을 매길 수 있습니다. 이렇게 되면 '새콤달달한 맛'에 대해 질문이 들어 왔을 때 이미 주어진 정보에는 이와 정확히 일치하는 표현이 없더라도 '신맛'이나 '단맛'에 대한 청크가 질문과 유사도가 높다고 판단할 수 있습니다.\"),\n",
       " Document(metadata={}, page_content='RAG 프로세스의 실행 단계 이해하기\\n이번에는 사전 단계 이후의 실행(runtime) 단계를 살펴보겠습니다.\\n- 5단계 | 리트리버: 질문이 주어지면, 이와 관련된 벡터를 벡터 데이터베이스에서 검색합니다. 질문에 가장 잘 맞는 책의 Chapter를 찾는 것과 유사합니다.\\n- 6단계 | 프롬프트: 검색된 정보를 바탕으로 언어 모델을 위한 질문을 구성합니다. 이는 정보를 바탕으로 어떻게 질문할지 결정하는 과정입니다.\\n- 7단계 | LLM: 구성된 프롬프트를 사용하여 언어 모델이 답변을 생성합니다. 즉, 수집된 정보를 바탕으로 과제나 보고서를 작성하는 학생과 같습니다.\\n- 8단계 | 체인 생성: 이전의 모든 과정을 하나의 파이프라인으로 묶어 주는 체인(chain)을 생성합니다.')]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "selected_docs = [Document(page_content=split_docs[doc]) for doc in selected_indices]\n",
    "selected_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f01db7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원래 요약을 다음과 같이 수정합니다:\n",
      "\n",
      "- RAG(검색 증강 생성)는 ChatGPT의 한계를 보완하기 위해 개발된 기술이다.\n",
      "- RAG는 거대 언어 모델이 외부의 신뢰할 수 있는 데이터베이스를 참조하여 응답을 생성하는 방식이다.\n",
      "- RAG를 활용하면 ChatGPT의 답변 품질을 50점에서 80점, 90점으로 향상시킬 수 있다.\n",
      "- 적절한 RAG 적용을 통해 ChatGPT의 문제점을 개선할 수 있다.\n",
      "- 또한, 국제유가 변동과 중국 경제 상황 변화가 주요 위험 요인으로 지적되며, 대외 불확실성에 대한 대응 방안을 모색하고 있다. 이 보고서는 정부 및 기업의 정책 결정에 중요한 정보를 제공하고, 경제 상황에 대한 깊은 이해와 미래 전망에 대한 지침을 포함하고 있다.\n",
      "\n",
      "-----------------\n",
      "\n",
      "\n",
      "- RAG(검색 증강 생성)는 ChatGPT의 한계를 보완하기 위해 개발된 기술이다.\n",
      "- RAG는 거대 언어 모델이 외부의 신뢰할 수 있는 데이터베이스를 참조하여 응답을 생성하는 방식이다.\n",
      "- RAG를 활용하면 ChatGPT의 답변 품질을 50점에서 80점, 90점으로 향상시킬 수 있다.\n",
      "- 적절한 RAG 적용을 통해 ChatGPT의 문제점을 개선할 수 있다.\n",
      "- 문서에서는 한국의 경제 상황과 전망에 중점을 두고 있으며, 국제유가 변동과 중국 경제 상황 변화가 주요 위험 요인으로 지적된다. 대외 불확실성에 대한 대응 방안을 모색하고 있으며, 이 보고서는 정부 및 기업의 정책 결정에 중요한 정보를 제공하고, 경제 상황에 대한 깊은 이해와 미래 전망에 대한 지침을 포함하고 있다.\n",
      "- 유로존의 실업률에 대한 구체적인 데이터는 제공되지 않으며, 해당 정보는 유럽연합 통계국(Eurostat) 웹사이트에서 확인할 수 있다.\n",
      "\n",
      "-----------------\n",
      "\n",
      "\n",
      "- RAG(검색 증강 생성)는 ChatGPT의 한계를 보완하기 위해 개발된 기술이다.\n",
      "- RAG는 거대 언어 모델이 외부의 신뢰할 수 있는 데이터베이스를 참조하여 응답을 생성하는 방식이다.\n",
      "- RAG를 활용하면 ChatGPT의 답변 품질을 50점에서 80점, 90점으로 향상시킬 수 있다.\n",
      "- 적절한 RAG 적용을 통해 ChatGPT의 문제점을 개선할 수 있다.\n",
      "- LangSmith라는 도구를 사용하여 LLM의 답변 추적 과정을 확인할 수 있으며, 질문을 입력하면 답변 도출 과정, 소요 시간, 토큰 수 등의 세부 정보를 제공한다.\n",
      "- Retriever 기능을 통해 관련 문서의 구절을 확인할 수 있으며, 문서 내용을 직접 열어볼 수 있다. 이러한 세부 분석을 통해 답변의 품질을 개선할 수 있는 원인을 추적할 수 있다.\n",
      "- 문서에서는 한국의 경제 상황과 전망에 중점을 두고 있으며, 국제유가 변동과 중국 경제 상황 변화가 주요 위험 요인으로 지적된다. 대외 불확실성에 대한 대응 방안을 모색하고 있으며, 이 보고서는 정부 및 기업의 정책 결정에 중요한 정보를 제공하고, 경제 상황에 대한 깊은 이해와 미래 전망에 대한 지침을 포함하고 있다.\n",
      "- 유로존의 실업률에 대한 구체적인 데이터는 제공되지 않으며, 해당 정보는 유럽연합 통계국(Eurostat) 웹사이트에서 확인할 수 있다.\n",
      "\n",
      "-----------------\n",
      "\n",
      "\n",
      "- RAG(검색 증강 생성)는 ChatGPT의 한계를 보완하기 위해 개발된 기술이다.\n",
      "- RAG는 거대 언어 모델이 외부의 신뢰할 수 있는 데이터베이스를 참조하여 응답을 생성하는 방식이다.\n",
      "- RAG를 활용하면 ChatGPT의 답변 품질을 50점에서 80점, 90점으로 향상시킬 수 있다.\n",
      "- 적절한 RAG 적용을 통해 ChatGPT의 문제점을 개선할 수 있다.\n",
      "- LangSmith라는 도구를 사용하여 LLM의 답변 추적 과정을 확인할 수 있으며, 질문을 입력하면 답변 도출 과정, 소요 시간, 토큰 수 등의 세부 정보를 제공한다.\n",
      "- Retriever 기능을 통해 관련 문서의 구절을 확인할 수 있으며, 문서 내용을 직접 열어볼 수 있다. 이러한 세부 분석을 통해 답변의 품질을 개선할 수 있는 원인을 추적할 수 있다.\n",
      "- LangChain을 통해 RAG 시스템의 모든 세부 프로세스를 구현하여 답변의 품질을 개선할 수 있다.\n",
      "- ChatGPT는 자체 RAG 시스템을 사용하지만, 세부 알고리즘 조정이 불가능하다는 한계가 있다.\n",
      "- RAG 시스템의 각 과정을 투명하게 개선하고 체계적으로 정립함으로써 다양한 비즈니스 환경에서 활용 가능한 성능을 달성할 수 있다.\n",
      "- 처음에는 복잡해 보일 수 있는 RAG 시스템의 전체 프로세스를 단계별로 익히면 이해하기 쉬워진다.\n",
      "- 문서에서는 한국의 경제 상황과 전망에 중점을 두고 있으며, 국제유가 변동과 중국 경제 상황 변화가 주요 위험 요인으로 지적된다. 대외 불확실성에 대한 대응 방안을 모색하고 있으며, 이 보고서는 정부 및 기업의 정책 결정에 중요한 정보를 제공하고, 경제 상황에 대한 깊은 이해와 미래 전망에 대한 지침을 포함하고 있다.\n",
      "- 유로존의 실업률에 대한 구체적인 데이터는 제공되지 않으며, 해당 정보는 유럽연합 통계국(Eurostat) 웹사이트에서 확인할 수 있다.\n",
      "\n",
      "-----------------\n",
      "\n",
      "\n",
      "- RAG(검색 증강 생성)는 ChatGPT의 한계를 보완하기 위해 개발된 기술이다.\n",
      "- RAG는 거대 언어 모델이 외부의 신뢰할 수 있는 데이터베이스를 참조하여 응답을 생성하는 방식이다.\n",
      "- RAG를 활용하면 ChatGPT의 답변 품질을 50점에서 80점, 90점으로 향상시킬 수 있다.\n",
      "- 적절한 RAG 적용을 통해 ChatGPT의 문제점을 개선할 수 있다.\n",
      "- RAG 프로세스는 GPT와 같은 LLM이 질문에 답변할 때 참고할 정보를 미리 저장하는 방법이다.\n",
      "- 사용자가 질문을 입력하면, RAG는 관련 문서를 데이터베이스에서 찾아 LLM에 제공하여 더 정확한 답변을 생성하도록 돕는다.\n",
      "- 기존의 LLM은 사전 학습된 정보만으로 답변을 제공하기 때문에 오래된 정보로 인한 오류가 발생할 수 있다. RAG는 이러한 문제를 해결하기 위해 실시간으로 관련 정보를 검색하여 활용한다.\n",
      "- LangSmith라는 도구를 사용하여 LLM의 답변 추적 과정을 확인할 수 있으며, 질문을 입력하면 답변 도출 과정, 소요 시간, 토큰 수 등의 세부 정보를 제공한다.\n",
      "- Retriever 기능을 통해 관련 문서의 구절을 확인할 수 있으며, 문서 내용을 직접 열어볼 수 있다. 이러한 세부 분석을 통해 답변의 품질을 개선할 수 있는 원인을 추적할 수 있다.\n",
      "- LangChain을 통해 RAG 시스템의 모든 세부 프로세스를 구현하여 답변의 품질을 개선할 수 있다.\n",
      "- ChatGPT는 자체 RAG 시스템을 사용하지만, 세부 알고리즘 조정이 불가능하다는 한계가 있다.\n",
      "- RAG 시스템의 각 과정을 투명하게 개선하고 체계적으로 정립함으로써 다양한 비즈니스 환경에서 활용 가능한 성능을 달성할 수 있다.\n",
      "- 처음에는 복잡해 보일 수 있는 RAG 시스템의 전체 프로세스를 단계별로 익히면 이해하기 쉬워진다.\n",
      "- 문서에서는 한국의 경제 상황과 전망에 중점을 두고 있으며, 국제유가 변동과 중국 경제 상황 변화가 주요 위험 요인으로 지적된다. 대외 불확실성에 대한 대응 방안을 모색하고 있으며, 이 보고서는 정부 및 기업의 정책 결정에 중요한 정보를 제공하고, 경제 상황에 대한 깊은 이해와 미래 전망에 대한 지침을 포함하고 있다.\n",
      "- 유로존의 실업률에 대한 구체적인 데이터는 제공되지 않으며, 해당 정보는 유럽연합 통계국(Eurostat) 웹사이트에서 확인할 수 있다.\n",
      "\n",
      "-----------------\n",
      "\n",
      "\n",
      "- RAG(검색 증강 생성)는 ChatGPT의 한계를 보완하기 위해 개발된 기술이다.\n",
      "- RAG는 거대 언어 모델이 외부의 신뢰할 수 있는 데이터베이스를 참조하여 응답을 생성하는 방식이다.\n",
      "- RAG를 활용하면 ChatGPT의 답변 품질을 50점에서 80점, 90점으로 향상시킬 수 있다.\n",
      "- 적절한 RAG 적용을 통해 ChatGPT의 문제점을 개선할 수 있다.\n",
      "- RAG 프로세스는 GPT와 같은 LLM이 질문에 답변할 때 참고할 정보를 미리 저장하는 방법이다.\n",
      "- 사용자가 질문을 입력하면, RAG는 관련 문서를 데이터베이스에서 찾아 LLM에 제공하여 더 정확한 답변을 생성하도록 돕는다.\n",
      "- 기존의 LLM은 사전 학습된 정보만으로 답변을 제공하기 때문에 오래된 정보로 인한 오류가 발생할 수 있다. RAG는 이러한 문제를 해결하기 위해 실시간으로 관련 정보를 검색하여 활용한다.\n",
      "- RAG 시스템의 3단계에서는 분할된 청크를 벡터 형태로 변환하여 문서의 의미를 수치화하는 임베딩 과정을 설명하고, 4단계에서는 임베딩된 청크를 데이터베이스에 저장하여 나중에 빠르게 찾을 수 있도록 정리하는 벡터 스토어 저장 과정을 다룬다.\n",
      "- LangSmith라는 도구를 사용하여 LLM의 답변 추적 과정을 확인할 수 있으며, 질문을 입력하면 답변 도출 과정, 소요 시간, 토큰 수 등의 세부 정보를 제공한다.\n",
      "- Retriever 기능을 통해 관련 문서의 구절을 확인할 수 있으며, 문서 내용을 직접 열어볼 수 있다. 이러한 세부 분석을 통해 답변의 품질을 개선할 수 있는 원인을 추적할 수 있다.\n",
      "- LangChain을 통해 RAG 시스템의 모든 세부 프로세스를 구현하여 답변의 품질을 개선할 수 있다.\n",
      "- ChatGPT는 자체 RAG 시스템을 사용하지만, 세부 알고리즘 조정이 불가능하다는 한계가 있다.\n",
      "- RAG 시스템의 각 과정을 투명하게 개선하고 체계적으로 정립함으로써 다양한 비즈니스 환경에서 활용 가능한 성능을 달성할 수 있다.\n",
      "- 처음에는 복잡해 보일 수 있는 RAG 시스템의 전체 프로세스를 단계별로 익히면 이해하기 쉬워진다.\n",
      "- 문서에서는 한국의 경제 상황과 전망에 중점을 두고 있으며, 국제유가 변동과 중국 경제 상황 변화가 주요 위험 요인으로 지적된다. 대외 불확실성에 대한 대응 방안을 모색하고 있으며, 이 보고서는 정부 및 기업의 정책 결정에 중요한 정보를 제공하고, 경제 상황에 대한 깊은 이해와 미래 전망에 대한 지침을 포함하고 있다.\n",
      "- 유로존의 실업률에 대한 구체적인 데이터는 제공되지 않으며, 해당 정보는 유럽연합 통계국(Eurostat) 웹사이트에서 확인할 수 있다.\n",
      "\n",
      "-----------------\n",
      "\n",
      "\n",
      "- RAG(검색 증강 생성)는 ChatGPT의 한계를 보완하기 위해 개발된 기술이다.\n",
      "- RAG는 거대 언어 모델이 외부의 신뢰할 수 있는 데이터베이스를 참조하여 응답을 생성하는 방식이다.\n",
      "- RAG를 활용하면 ChatGPT의 답변 품질을 50점에서 80점, 90점으로 향상시킬 수 있다.\n",
      "- 적절한 RAG 적용을 통해 ChatGPT의 문제점을 개선할 수 있다.\n",
      "- RAG 프로세스는 GPT와 같은 LLM이 질문에 답변할 때 참고할 정보를 미리 저장하는 방법이다.\n",
      "- 사용자가 질문을 입력하면, RAG는 관련 문서를 데이터베이스에서 찾아 LLM에 제공하여 더 정확한 답변을 생성하도록 돕는다.\n",
      "- 기존의 LLM은 사전 학습된 정보만으로 답변을 제공하기 때문에 오래된 정보로 인한 오류가 발생할 수 있다. RAG는 이러한 문제를 해결하기 위해 실시간으로 관련 정보를 검색하여 활용한다.\n",
      "- RAG 시스템의 3단계에서는 분할된 청크를 벡터 형태로 변환하여 문서의 의미를 수치화하는 임베딩 과정을 설명하고, 4단계에서는 임베딩된 청크를 데이터베이스에 저장하여 나중에 빠르게 찾을 수 있도록 정리하는 벡터 스토어 저장 과정을 다룬다.\n",
      "- 문서 로드 단계에서는 다양한 형식의 문서를 불러와 텍스트를 추출하고, 텍스트 분할 과정에서는 필요한 정보만을 청크 단위로 나누어 사용한다. 청크 크기는 토큰 수를 기준으로 설정되며, 예를 들어 1,000토큰으로 지정할 수 있다.\n",
      "- LangSmith라는 도구를 사용하여 LLM의 답변 추적 과정을 확인할 수 있으며, 질문을 입력하면 답변 도출 과정, 소요 시간, 토큰 수 등의 세부 정보를 제공한다.\n",
      "- Retriever 기능을 통해 관련 문서의 구절을 확인할 수 있으며, 문서 내용을 직접 열어볼 수 있다. 이러한 세부 분석을 통해 답변의 품질을 개선할 수 있는 원인을 추적할 수 있다.\n",
      "- LangChain을 통해 RAG 시스템의 모든 세부 프로세스를 구현하여 답변의 품질을 개선할 수 있다.\n",
      "- ChatGPT는 자체 RAG 시스템을 사용하지만, 세부 알고리즘 조정이 불가능하다는 한계가 있다.\n",
      "- RAG 시스템의 각 과정을 투명하게 개선하고 체계적으로 정립함으로써 다양한 비즈니스 환경에서 활용 가능한 성능을 달성할 수 있다.\n",
      "- 처음에는 복잡해 보일 수 있는 RAG 시스템의 전체 프로세스를 단계별로 익히면 이해하기 쉬워진다.\n",
      "- 문서에서는 한국의 경제 상황과 전망에 중점을 두고 있으며, 국제유가 변동과 중국 경제 상황 변화가 주요 위험 요인으로 지적된다. 대외 불확실성에 대한 대응 방안을 모색하고 있으며, 이 보고서는 정부 및 기업의 정책 결정에 중요한 정보를 제공하고, 경제 상황에 대한 깊은 이해와 미래 전망에 대한 지침을 포함하고 있다.\n",
      "- 유로존의 실업률에 대한 구체적인 데이터는 제공되지 않으며, 해당 정보는 유럽연합 통계국(Eurostat) 웹사이트에서 확인할 수 있다.\n",
      "\n",
      "-----------------\n",
      "\n",
      "\n",
      "- RAG(검색 증강 생성)는 ChatGPT의 한계를 보완하기 위해 개발된 기술이다.\n",
      "- RAG는 거대 언어 모델이 외부의 신뢰할 수 있는 데이터베이스를 참조하여 응답을 생성하는 방식이다.\n",
      "- RAG를 활용하면 ChatGPT의 답변 품질을 50점에서 80점, 90점으로 향상시킬 수 있다.\n",
      "- 적절한 RAG 적용을 통해 ChatGPT의 문제점을 개선할 수 있다.\n",
      "- RAG 프로세스는 GPT와 같은 LLM이 질문에 답변할 때 참고할 정보를 미리 저장하는 방법이다.\n",
      "- 사용자가 질문을 입력하면, RAG는 관련 문서를 데이터베이스에서 찾아 LLM에 제공하여 더 정확한 답변을 생성하도록 돕는다.\n",
      "- 기존의 LLM은 사전 학습된 정보만으로 답변을 제공하기 때문에 오래된 정보로 인한 오류가 발생할 수 있다. RAG는 이러한 문제를 해결하기 위해 실시간으로 관련 정보를 검색하여 활용한다.\n",
      "- RAG 시스템의 3단계에서는 분할된 청크를 벡터 형태로 변환하여 문서의 의미를 수치화하는 임베딩 과정을 설명하고, 4단계에서는 임베딩된 청크를 데이터베이스에 저장하여 나중에 빠르게 찾을 수 있도록 정리하는 벡터 스토어 저장 과정을 다룬다.\n",
      "- 문서 로드 단계에서는 다양한 형식의 문서를 불러와 텍스트를 추출하고, 텍스트 분할 과정에서는 필요한 정보만을 청크 단위로 나누어 사용한다. 청크 크기는 토큰 수를 기준으로 설정되며, 예를 들어 1,000토큰으로 지정할 수 있다.\n",
      "- LangSmith라는 도구를 사용하여 LLM의 답변 추적 과정을 확인할 수 있으며, 질문을 입력하면 답변 도출 과정, 소요 시간, 토큰 수 등의 세부 정보를 제공한다.\n",
      "- Retriever 기능을 통해 관련 문서의 구절을 확인할 수 있으며, 문서 내용을 직접 열어볼 수 있다. 이러한 세부 분석을 통해 답변의 품질을 개선할 수 있는 원인을 추적할 수 있다.\n",
      "- LangChain을 통해 RAG 시스템의 모든 세부 프로세스를 구현하여 답변의 품질을 개선할 수 있다.\n",
      "- ChatGPT는 자체 RAG 시스템을 사용하지만, 세부 알고리즘 조정이 불가능하다는 한계가 있다.\n",
      "- RAG 시스템의 각 과정을 투명하게 개선하고 체계적으로 정립함으로써 다양한 비즈니스 환경에서 활용 가능한 성능을 달성할 수 있다.\n",
      "- 처음에는 복잡해 보일 수 있는 RAG 시스템의 전체 프로세스를 단계별로 익히면 이해하기 쉬워진다.\n",
      "- 사용자 질문에 대해 유사도를 계산하여 가장 관련성이 높은 청크를 선택하는 작업을 수행하며, 이를 위해 청크의 값을 수학적으로 표현하는 임베딩 과정을 거친다. 임베딩을 통해 자연어의 복잡한 의미를 정량화된 숫자 값으로 변환하여 컴퓨터가 이해할 수 있도록 한다. 예를 들어, '매운맛', '신맛', '단맛'을 각각 숫자로 표현하여 사용자가 입력한 '새콤달달한 맛'과의 유사도를 계산할 수 있다.\n",
      "- 문서에서는 한국의 경제 상황과 전망에 중점을 두고 있으며, 국제유가 변동과 중국 경제 상황 변화가 주요 위험 요인으로 지적된다. 대외 불확실성에 대한 대응 방안을 모색하고 있으며, 이 보고서는 정부 및 기업의 정책 결정에 중요한 정보를 제공하고, 경제 상황에 대한 깊은 이해와 미래 전망에 대한 지침을 포함하고 있다.\n",
      "- 유로존의 실업률에 대한 구체적인 데이터는 제공되지 않으며, 해당 정보는 유럽연합 통계국(Eurostat) 웹사이트에서 확인할 수 있다.\n",
      "\n",
      "-----------------\n",
      "\n",
      "\n",
      "- RAG(검색 증강 생성)는 ChatGPT의 한계를 보완하기 위해 개발된 기술이다.\n",
      "- RAG는 거대 언어 모델이 외부의 신뢰할 수 있는 데이터베이스를 참조하여 응답을 생성하는 방식이다.\n",
      "- RAG를 활용하면 ChatGPT의 답변 품질을 50점에서 80점, 90점으로 향상시킬 수 있다.\n",
      "- 적절한 RAG 적용을 통해 ChatGPT의 문제점을 개선할 수 있다.\n",
      "- RAG 프로세스는 GPT와 같은 LLM이 질문에 답변할 때 참고할 정보를 미리 저장하는 방법이다.\n",
      "- 사용자가 질문을 입력하면, RAG는 관련 문서를 데이터베이스에서 찾아 LLM에 제공하여 더 정확한 답변을 생성하도록 돕는다.\n",
      "- 기존의 LLM은 사전 학습된 정보만으로 답변을 제공하기 때문에 오래된 정보로 인한 오류가 발생할 수 있다. RAG는 이러한 문제를 해결하기 위해 실시간으로 관련 정보를 검색하여 활용한다.\n",
      "- RAG 시스템의 3단계에서는 분할된 청크를 벡터 형태로 변환하여 문서의 의미를 수치화하는 임베딩 과정을 설명하고, 4단계에서는 임베딩된 청크를 데이터베이스에 저장하여 나중에 빠르게 찾을 수 있도록 정리하는 벡터 스토어 저장 과정을 다룬다.\n",
      "- 문서 로드 단계에서는 다양한 형식의 문서를 불러와 텍스트를 추출하고, 텍스트 분할 과정에서는 필요한 정보만을 청크 단위로 나누어 사용한다. 청크 크기는 토큰 수를 기준으로 설정되며, 예를 들어 1,000토큰으로 지정할 수 있다.\n",
      "- LangSmith라는 도구를 사용하여 LLM의 답변 추적 과정을 확인할 수 있으며, 질문을 입력하면 답변 도출 과정, 소요 시간, 토큰 수 등의 세부 정보를 제공한다.\n",
      "- Retriever 기능을 통해 관련 문서의 구절을 확인할 수 있으며, 문서 내용을 직접 열어볼 수 있다. 이러한 세부 분석을 통해 답변의 품질을 개선할 수 있는 원인을 추적할 수 있다.\n",
      "- LangChain을 통해 RAG 시스템의 모든 세부 프로세스를 구현하여 답변의 품질을 개선할 수 있다.\n",
      "- ChatGPT는 자체 RAG 시스템을 사용하지만, 세부 알고리즘 조정이 불가능하다는 한계가 있다.\n",
      "- RAG 시스템의 각 과정을 투명하게 개선하고 체계적으로 정립함으로써 다양한 비즈니스 환경에서 활용 가능한 성능을 달성할 수 있다.\n",
      "- 처음에는 복잡해 보일 수 있는 RAG 시스템의 전체 프로세스를 단계별로 익히면 이해하기 쉬워진다.\n",
      "- 사용자 질문에 대해 유사도를 계산하여 가장 관련성이 높은 청크를 선택하는 작업을 수행하며, 이를 위해 청크의 값을 수학적으로 표현하는 임베딩 과정을 거친다. 임베딩을 통해 자연어의 복잡한 의미를 정량화된 숫자 값으로 변환하여 컴퓨터가 이해할 수 있도록 한다. 예를 들어, '매운맛', '신맛', '단맛'을 각각 숫자로 표현하여 사용자가 입력한 '새콤달달한 맛'과의 유사도를 계산할 수 있다.\n",
      "- 문서에서는 한국의 경제 상황과 전망에 중점을 두고 있으며, 국제유가 변동과 중국 경제 상황 변화가 주요 위험 요인으로 지적된다. 대외 불확실성에 대한 대응 방안을 모색하고 있으며, 이 보고서는 정부 및 기업의 정책 결정에 중요한 정보를 제공하고, 경제 상황에 대한 깊은 이해와 미래 전망에 대한 지침을 포함하고 있다.\n",
      "- 유로존의 실업률에 대한 구체적인 데이터는 제공되지 않으며, 해당 정보는 유럽연합 통계국(Eurostat) 웹사이트에서 확인할 수 있다.\n",
      "- RAG 프로세스의 실행 단계는 5단계부터 8단계까지 구성되어 있다. 5단계에서는 질문에 맞는 벡터를 데이터베이스에서 검색하여 관련 정보를 찾고, 6단계에서는 검색된 정보를 바탕으로 언어 모델에 대한 질문을 구성한다. 7단계에서는 구성된 프롬프트를 사용하여 언어 모델이 답변을 생성하며, 8단계에서는 이전 단계들을 하나의 파이프라인으로 연결하는 체인을 생성한다.\n",
      "\n",
      "-----------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 이전에 생성한 map_refine_chain을 사용하여 요약 생성\n",
    "refined_summary = map_refine_chain.invoke(selected_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "961a16e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- RAG(검색 증강 생성)는 ChatGPT의 한계를 보완하기 위해 개발된 기술이다.\n",
      "- RAG는 거대 언어 모델이 외부의 신뢰할 수 있는 데이터베이스를 참조하여 응답을 생성하는 방식이다.\n",
      "- RAG를 활용하면 ChatGPT의 답변 품질을 50점에서 80점, 90점으로 향상시킬 수 있다.\n",
      "- 적절한 RAG 적용을 통해 ChatGPT의 문제점을 개선할 수 있다.\n",
      "- RAG 프로세스는 GPT와 같은 LLM이 질문에 답변할 때 참고할 정보를 미리 저장하는 방법이다.\n",
      "- 사용자가 질문을 입력하면, RAG는 관련 문서를 데이터베이스에서 찾아 LLM에 제공하여 더 정확한 답변을 생성하도록 돕는다.\n",
      "- 기존의 LLM은 사전 학습된 정보만으로 답변을 제공하기 때문에 오래된 정보로 인한 오류가 발생할 수 있다. RAG는 이러한 문제를 해결하기 위해 실시간으로 관련 정보를 검색하여 활용한다.\n",
      "- RAG 시스템의 3단계에서는 분할된 청크를 벡터 형태로 변환하여 문서의 의미를 수치화하는 임베딩 과정을 설명하고, 4단계에서는 임베딩된 청크를 데이터베이스에 저장하여 나중에 빠르게 찾을 수 있도록 정리하는 벡터 스토어 저장 과정을 다룬다.\n",
      "- 문서 로드 단계에서는 다양한 형식의 문서를 불러와 텍스트를 추출하고, 텍스트 분할 과정에서는 필요한 정보만을 청크 단위로 나누어 사용한다. 청크 크기는 토큰 수를 기준으로 설정되며, 예를 들어 1,000토큰으로 지정할 수 있다.\n",
      "- LangSmith라는 도구를 사용하여 LLM의 답변 추적 과정을 확인할 수 있으며, 질문을 입력하면 답변 도출 과정, 소요 시간, 토큰 수 등의 세부 정보를 제공한다.\n",
      "- Retriever 기능을 통해 관련 문서의 구절을 확인할 수 있으며, 문서 내용을 직접 열어볼 수 있다. 이러한 세부 분석을 통해 답변의 품질을 개선할 수 있는 원인을 추적할 수 있다.\n",
      "- LangChain을 통해 RAG 시스템의 모든 세부 프로세스를 구현하여 답변의 품질을 개선할 수 있다.\n",
      "- ChatGPT는 자체 RAG 시스템을 사용하지만, 세부 알고리즘 조정이 불가능하다는 한계가 있다.\n",
      "- RAG 시스템의 각 과정을 투명하게 개선하고 체계적으로 정립함으로써 다양한 비즈니스 환경에서 활용 가능한 성능을 달성할 수 있다.\n",
      "- 처음에는 복잡해 보일 수 있는 RAG 시스템의 전체 프로세스를 단계별로 익히면 이해하기 쉬워진다.\n",
      "- 사용자 질문에 대해 유사도를 계산하여 가장 관련성이 높은 청크를 선택하는 작업을 수행하며, 이를 위해 청크의 값을 수학적으로 표현하는 임베딩 과정을 거친다. 임베딩을 통해 자연어의 복잡한 의미를 정량화된 숫자 값으로 변환하여 컴퓨터가 이해할 수 있도록 한다. 예를 들어, '매운맛', '신맛', '단맛'을 각각 숫자로 표현하여 사용자가 입력한 '새콤달달한 맛'과의 유사도를 계산할 수 있다.\n",
      "- 문서에서는 한국의 경제 상황과 전망에 중점을 두고 있으며, 국제유가 변동과 중국 경제 상황 변화가 주요 위험 요인으로 지적된다. 대외 불확실성에 대한 대응 방안을 모색하고 있으며, 이 보고서는 정부 및 기업의 정책 결정에 중요한 정보를 제공하고, 경제 상황에 대한 깊은 이해와 미래 전망에 대한 지침을 포함하고 있다.\n",
      "- 유로존의 실업률에 대한 구체적인 데이터는 제공되지 않으며, 해당 정보는 유럽연합 통계국(Eurostat) 웹사이트에서 확인할 수 있다.\n",
      "- RAG 프로세스의 실행 단계는 5단계부터 8단계까지 구성되어 있다. 5단계에서는 질문에 맞는 벡터를 데이터베이스에서 검색하여 관련 정보를 찾고, 6단계에서는 검색된 정보를 바탕으로 언어 모델에 대한 질문을 구성한다. 7단계에서는 구성된 프롬프트를 사용하여 언어 모델이 답변을 생성하며, 8단계에서는 이전 단계들을 하나의 파이프라인으로 연결하는 체인을 생성한다.\n"
     ]
    }
   ],
   "source": [
    "# 최종 결과 출력\n",
    "print(refined_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-Us6BDj1P-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
